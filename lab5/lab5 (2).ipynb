{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "###  Business Case Explanation\n",
    "(mostly the same processes as from lab four) Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). Detail exactly what the task is and what parties would be interested in the results. How well would your prediction algorithm need to perform to be considered useful by interested parties?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Our Problem\n",
    "There are literally tens of thousands of movies out there today. While some do great at the box office and bring in a lot of money, others flop making only a fraction compared to the top hits. What if we had a scientific way of accurately predicting how much revenue a movie would generate over its lifetime? Well, through machine learning we believe that we actually can!\n",
    "\n",
    "The dataset we are using is found on <a href=\"https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset\">Kaggle</a>. It consists of 5000+ movies scraped from the review site IMDB. There is quite a bit of data recorded for each movie and so we had a lot to work with to try to predict the next big hit. The data was collected from web scraping IMDB using a python library called \"scrappy\" to collect all of the data below. The features recorded for each movie are: \n",
    "\n",
    "Basic Info:\n",
    "- movie title\n",
    "- color (black and white or color)\t\n",
    "- duration of the movie\n",
    "- director name\n",
    "- gross (total revenue)\n",
    "- genres (a lits of different genres ascribed to the movie)\n",
    "- number of faces in movie poster\n",
    "- language of the movie\n",
    "- country the movie was produced in\n",
    "- content rating (G, PG, PG-13, R, NC-17)\n",
    "- budget\n",
    "- year of release\n",
    "- aspect ratio\n",
    "- name of the 3rd actor\n",
    "- name of the 2nd actor\n",
    "- name of the 1st actor\n",
    "\n",
    "Facebook Info:\n",
    "- number of director facebook likes\n",
    "- number of facebook likes for the whole cast\n",
    "- number of the movie's facebook likes\n",
    "- number of the 3rd actor's facebook likes\n",
    "- number of the 2nd actor's facebook likes\n",
    "- number of the 1st actor's facebook likes\n",
    "\n",
    "IMDB Specific Info:\n",
    "- number of imdb users who rated the movie\n",
    "- number of critical reviews for the movie\n",
    "- number of users who left a review\n",
    "- imdb score\n",
    "- top plot keywords\n",
    "\n",
    "\n",
    "With all of this data collected on so many movies, we hope to be able to use this to build out a multi-layer perceptron  to accurately predict the financial success (measured in categories of gross revenue: low, low-mid, high-mid, and high) of a movie. We think that this could be a useful tool to anyone in the movie industry who is concerned with making a profit on their movie. It could also help a producer understand which of these features are the most important to an accurate prediction, what content rating is most important, how budget affects outcome, etc.\n",
    "\n",
    "\n",
    "We believe that the algorithm would have to predict with a relatively low cost (under ~30) to be found useful by movie directors, producers, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and Preparing Class Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing:\n",
    "We made a number of changes to both the original csv obtained from kaggle before we loaded it and to the data once it was loaded in.\n",
    "\n",
    "\n",
    "Pre-processing of the CSV:\n",
    "- We first removed the imdb link from the csv because we knew we would never need to use that (**Note: this was the only feature removed from the csv**)\n",
    "- We then went through and deleted all of the movies that were made in another country (foriegn films) we did this because we wanted to just look at American films, also because the currency units for those countries (for budget and gross) were in native currency units, not USD, and with changing exchange rates, it's not very easy to compare across countries.\n",
    "- We then went through and converted all 0 values for gross, movie_facebook_likes, and director_facebook_likes to a blank value in the csv (so that it is read in as NaN by pandas), this is so that we cna more easily impute values later. Note: according to the description on the kaggle entry, because of the way the data was scraped, some movies had missing data. The Python scraper just made these values into a 0 instead of NaN.\n",
    "- We then removed all movies with an undefined gross. Being the feature we are trying to predict, we should not be imputing values for gross to train our model. That will basically reduce our model to an imputation algorithm...\n",
    "- We then removed all movies that were made before 1935. We did this because there were only a handful of movies ranging from 1915 to 1935, the way we are classifying budget (described below) would not work with a small sample of movies from that time period. We could have cut this number at a different year (say 1960), but we didn't want to exclude such classics as \"Bambi\" or \"Gone With the Wind\"\n",
    "- Lastly, we had to adjust the gross revenue and budget values for inflation, since the movies spanned many years. For adjusting for inflation we obtained a csv of consumer price index (CPI) for every month since 1947. To simplify, we just took the value for January of that year to use for the whole year. We then took the CPI and calculated the ratio per year compared to 2017 dollars. We then took the budget and gross and multiplied them out with their appropriate ratio value. We then exported this to the csv that we use for the rest of this lab. **NB:** This was done outside of this notebook because this whole process took a very long time when it was included in the notebook when done every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing of the Data:\n",
    "- After the above steps, we made more edits to the data using pandas. First, we removed features that we thought would be un-useful to our prediction algorithm. We removed all features concerning facebook likes. We did this because a significant portion of the movies in the training set debuted before facebook was invented and widely adopted. While some of these movies have received retroactive \"likes\" on facebook, only the most famous classics received a substantial amount of retraoctive \"likes\". Most lesser known films received very low amounts of \"likes\" (presumably because modern movie watchers don't really care to search for lesser known movies on facebook, or because the movie doesn't have a facebook). For this reason we decided to remove movie_facebook_likes\n",
    "- Likewise, we removed the other \"likes\" for the same reasons as above. For example, the esteemed director George Lucas has a total of 0 \"likes\" between all of his films. This feature obviously would not help us predict the profitability of movies.\n",
    "- We also removed irrelevant information such as aspect_ratio, language, and country. Because we deleted all foreign films the country will always be USA. A simple filter of the data reveals that there are no more than 20 movies made in the US that use a language other than English, therefore there is not enough data to use language as training feature. However, we did not delete the movies in a different language, because most of them were famous films such as *Letters from Iwo Jima* and *The Kite Runner*. We still count them as a valuable part of the dataset, just don't find the language of particular value. Lastly, we removed aspect_ratio because that seems to be unimportant for predicting the success of a movie.\n",
    "- Lastly, we removed other features that would be difficult to use in our machine learning model such as actor names and plot keywords. We initially tried to include these in our model using one-hot encoding, but the resultant array was so enormous that the model would take a very, very long time to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Time and Memory Profiler, Reading in Data\n",
    "Below we import a memory profiler to use later on in this notebook, along with reading in the movie data as discussed above. The unneccesary features are dropped out of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext memory_profiler\n",
    "import timeit\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3222 entries, 0 to 3221\n",
      "Data columns (total 12 columns):\n",
      "director_name             3222 non-null object\n",
      "num_critic_for_reviews    3219 non-null float64\n",
      "duration                  3221 non-null float64\n",
      "gross                     3222 non-null int64\n",
      "actor_1_name              3220 non-null object\n",
      "num_voted_users           3222 non-null int64\n",
      "facenumber_in_poster      3216 non-null float64\n",
      "num_user_for_reviews      3221 non-null float64\n",
      "content_rating            3196 non-null object\n",
      "budget                    3062 non-null float64\n",
      "title_year                3222 non-null int64\n",
      "imdb_score                3222 non-null float64\n",
      "dtypes: float64(6), int64(3), object(3)\n",
      "memory usage: 302.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Take the dataframe and adjust for inflation and then use the df_to_csv function to export to csv \n",
    "# and then export to csv and then delete code\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"inflation_corrected_dataset.csv\")\n",
    "for x in ['movie_facebook_likes', 'director_facebook_likes', 'actor_2_facebook_likes', \n",
    "          'actor_1_facebook_likes','actor_3_facebook_likes', 'cast_total_facebook_likes',\n",
    "          'aspect_ratio', 'language', 'country', 'plot_keywords', 'actor_3_name', 'actor_2_name', 'movie_title', 'genres', 'color']:\n",
    "    if x in df:\n",
    "        del df[x]\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we group the columns by director_name and then impute as many values as we can, dropping the rows where we can't impute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tamper with the groupings to improve imputations? How do we improve how many values get imputed?\n",
    "df_grouped = df.groupby(by=['director_name'])\n",
    "# director_name adds about 50 rows (imputes about 50 rows and then deletes about 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3127 entries, 0 to 3220\n",
      "Data columns (total 12 columns):\n",
      "num_critic_for_reviews    3127 non-null float64\n",
      "duration                  3127 non-null float64\n",
      "gross                     3127 non-null int64\n",
      "num_voted_users           3127 non-null int64\n",
      "facenumber_in_poster      3127 non-null float64\n",
      "num_user_for_reviews      3127 non-null float64\n",
      "budget                    3127 non-null float64\n",
      "title_year                3127 non-null int64\n",
      "imdb_score                3127 non-null float64\n",
      "actor_1_name              3127 non-null object\n",
      "content_rating            3127 non-null object\n",
      "director_name             3127 non-null object\n",
      "dtypes: float64(6), int64(3), object(3)\n",
      "memory usage: 317.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_imputed = df_grouped.transform(lambda grp: grp.fillna(grp.median()))\n",
    "col_deleted = list( set(df.columns) - set(df_imputed.columns)) #in case the median op deleted columns\n",
    "df_imputed[col_deleted] = df[col_deleted]\n",
    "\n",
    "# drop rows that still have missing values after imputation\n",
    "df_imputed.dropna(inplace=True)\n",
    "print(df_imputed.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the Data\n",
    "Below we scale the data using the methods shown so as to not adversely affect the gamma value. We scaled down all of the numerical values to be within -1 and 1. We also one-hot encode the content rating. We forego encoding the director name or actor names because they proved to make our matrix way too large to run computations on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df:  (3127, 12)\n",
      "(3127, 12)\n",
      "Wall time: 6.52 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#scaling budgets!\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "budget = df_imputed['budget'].values.reshape(-1, 1)\n",
    "df_imputed.reset_index(drop=True, inplace=True)\n",
    "print(\"df: \",df_imputed.shape)\n",
    "\n",
    "append_list = [df_imputed]\n",
    "\n",
    "df = pd.concat(append_list, axis=1)\n",
    "\n",
    "#one-hot encode\n",
    "hot_content = pd.get_dummies(df_imputed.content_rating, prefix='contentRating')\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting the gross into categories\n",
    "Below we cut the adjusted, scaled, gross into 4 main categories: low, low-mid, high-mid, and high. We did this because otherwise the model would not be able to produce raw gross accurately. We also used the \"qcut\" function to evenly distribute the classes among the classifications, because when we did a normal cut method most of the classes would fall in the lowest category and throw off our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "spacing = np.linspace(0, max(df['gross']), 100)\n",
    "labels = []\n",
    "\n",
    "labels = [\"low\", \"low-mid\", \"high-mid\", \"high\"]\n",
    "df['gross_group'] = pd.qcut(df['gross'], 4, labels=labels)\n",
    "\n",
    "\n",
    "rating_group = df['gross_group'].values\n",
    "rating_encoder = LabelEncoder()\n",
    "rating_df = pd.DataFrame(rating_encoder.fit_transform(rating_group), columns=['encoded_gross']).astype(str)\n",
    "df = pd.concat([df, rating_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "### Choosing Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our dataset, accuracy is not the best evaluation metric, because that does not account properly for false positives. False positives for our business case are MUCH worse than a false negative. It would be very bad to predict that a movie will gross high, when in fact it grosses lowly. However, if we predict the movie will gross low, and it ends up grossing highly, that isn't as bad, because the director will either be pleasantly surprised, or he will choose to not undertake the filming in the first place. It is better to not film and miss out on the potential money, than to undertake the film thinking that it would be lucrative, when in fact it is not.\n",
    "\n",
    "Because we are using a multi-class classification model we can not simply use precision, recall, or f1 score, but must construct a cost matrix with different weights that correspond to the different combination of predictions and results. Below we have our cost matrix defined. As you can see we weight a false positive with a 20 and a false negative with a 6. We give them this much of a cost difference because of the aforementioned reasons about false positives. Any True predictions are a negative one, and the other numbers in the matrix are scaled appropriately dependent upon how bad they would be as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 10 14 20]\n",
      " [ 2 -1 10 14]\n",
      " [ 4  2 -1 10]\n",
      " [ 6  4  2 -1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cost_matrix = np.array([-1,10, 14,20,2,-1,10,14,4,2,-1,10,6,4,2,-1]) #give a reason for why these numbers chosen\n",
    "cost_matrix = cost_matrix.reshape(4,4)\n",
    "print(cost_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing up training/testing data\n",
    "Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our dataset we want to use Stratified 10-fold cross validation because it is the best and works for our dataset well. Below we create the StratifiedKFold object and then use it many times later on in the lab. We selected this method instead of a simple 80/20 split because we new that we wanted to test on multiple randomized sets of data, instead of just the same one, so as to avoid data snooping and improper parameter tuning. We chose not to use the shuffle option becuase we wanted to compare our custom implementation and scikit-learn using the same indices for training and testing data. Below we also drop a few more fields that we no longer need due to categorizing the gross, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "drop_list = ['encoded_gross', 'gross_group', \n",
    "              'gross', 'director_name', 'actor_1_name', 'content_rating']\n",
    "X = df.drop(drop_list, axis=1).values\n",
    "y = df['encoded_gross'].values.astype(np.float) # x and y are now np.matrices \n",
    "\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "### Creating Our Custom MLP\n",
    "Below we have a number of classes and subclasses to form our custom MLP, this will allow for a sigmoide, linear, or relu nonlinearity and a quadratic or cross entropy cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example adapted from https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb\n",
    "# Original Author: Sebastian Raschka\n",
    "# This is the optional book we use in the course, excellent intuitions and straightforward programming examples\n",
    "# please note, however, that this code has been manipulated to reflect our assumptions and notation.\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# start with a simple base classifier, which can't be fit or predicted\n",
    "# it only has internal classes to be used by classes that will subclass it\n",
    "class TwoLayerPerceptronBase(object):\n",
    "    def __init__(self, n_hidden=30, nonlinear=\"sigmoid\",\n",
    "                 C=0.0, epochs=500, eta=0.001, random_state=None):\n",
    "        np.random.seed(random_state)\n",
    "        self.nonlinear = nonlinear\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "            \n",
    "        return onehot\n",
    "    \n",
    "    #Initialization used in RELU\n",
    "    def _initialize_weights(self):\n",
    "        if self.nonlinear == \"linear\":\n",
    "            const1 = 6.\n",
    "            const2 = 6.\n",
    "        elif self.nonlinear == \"sigmoid\":\n",
    "            const1 = 2.\n",
    "            const2 = 2.\n",
    "        elif self.nonlinear == \"relu\":\n",
    "            const1 = 6.\n",
    "            const2 = 2.\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        # suggested relu/sigmoid bounds\n",
    "        # Glorot, Xavier, Antoine Bordes, and Yoshua Bengio. \n",
    "        #   \"Deep Sparse Rectifier Neural Networks.\"\n",
    "        init_bound = np.sqrt(const1 / (self.n_hidden + self.n_features_ + 1))\n",
    "        W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_ + 1))\n",
    "\n",
    "        init_bound = np.sqrt( const2 / (self.n_output_ + self.n_hidden + 1))\n",
    "        W2 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden + 1))\n",
    "        return W1, W2\n",
    "    \n",
    "    @staticmethod\n",
    "    def _relu(Z):\n",
    "        return np.maximum(0,Z.copy())\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        \"\"\"Use scipy.special.expit to avoid overflow\"\"\"\n",
    "        # 1.0 / (1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new\n",
    "    \n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, W1, W2):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        # only compute for non-bias terms\n",
    "        return (lambda_/2.0) * np.sqrt(np.mean(W1[:, 1:] ** 2) + np.mean(W2[:, 1:] ** 2))\n",
    "    \n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = np.mean((Y_enc-A3)**2)\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _feedforward(self, X, W1, W2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        \"\"\"\n",
    "        A1 = self._add_bias_unit(X, how='column')\n",
    "        Z1 = W1 @ A1.T\n",
    "        if self.nonlinear == \"sigmoid\":  #A1->W1->Sigmoid->A2->W2->Sigmoid\n",
    "            A2 = self._sigmoid(Z1)\n",
    "        elif self.nonlinear == \"linear\": #A1->W1->Linear->A2->W2->Linear\n",
    "            A2 = Z1\n",
    "        elif self.nonlinear == \"relu\": #A1->W1->Relu->A2->W2->Sigmoid\n",
    "            A2 = self._relu(Z1)\n",
    "        A2 = self._add_bias_unit(A2, how='row')\n",
    "        Z2 = W2 @ A2\n",
    "        if self.nonlinear == 'sigmoid' or self.nonlinear == 'relu':\n",
    "            A3 = self._sigmoid(Z2)\n",
    "        elif self.nonlinear == 'linear':\n",
    "            A3 = Z2\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        if self.nonlinear == 'sigmoid': \n",
    "            sigma3 = -2*(Y_enc-A3)*A3*(1-A3)\n",
    "            sigma2 = (W2.T @ sigma3)*A2*(1-A2)\n",
    "        elif self.nonlinear == 'linear':\n",
    "            sigma3 = -2*(Y_enc-A3)\n",
    "            sigma2 = (W2.T @ sigma3)\n",
    "        elif self.nonlinear == 'relu':\n",
    "            sigma3 = (A3-Y_enc) \n",
    "            sigma2 = (W2.T @ sigma3) \n",
    "            Z1_with_bias = self._add_bias_unit(Z1,how='row')\n",
    "            sigma2[Z1_with_bias<=0] = 0\n",
    "\n",
    "        grad1 = sigma2[1:,:] @ A1\n",
    "        grad2 = sigma3 @ A2.T\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        grad1[:, 1:] += W1[:, 1:] * self.l2_C\n",
    "        grad2[:, 1:] += W2[:, 1:] * self.l2_C\n",
    "\n",
    "        return grad1, grad2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        _, _, _, _, A3 = self._feedforward(X, self.W1, self.W2)\n",
    "        y_pred = np.argmax(A3, axis=0)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# just start with the vectorized version and minibatch\n",
    "class TLPMiniBatch(TwoLayerPerceptronBase):\n",
    "    def __init__(self, alpha=0.0, decrease_const=0.0, shuffle=True, \n",
    "                 minibatches=1, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.alpha = alpha\n",
    "        self.decrease_const = decrease_const\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatches = minibatches\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2 = self._initialize_weights()\n",
    "\n",
    "        delta_W1_prev = np.zeros(self.W1.shape)\n",
    "        delta_W2_prev = np.zeros(self.W2.shape)\n",
    "\n",
    "        self.cost_ = []\n",
    "        self.score_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # adaptive learning rate\n",
    "            self.eta /= (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
    "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       self.W1,\n",
    "                                                       self.W2)\n",
    "                \n",
    "                cost = self._cost(A3,Y_enc[:, idx],self.W1,self.W2)\n",
    "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                grad1, grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2, \n",
    "                                                  Y_enc=Y_enc[:, idx],\n",
    "                                                  W1=self.W1,W2=self.W2)\n",
    "\n",
    "                delta_W1, delta_W2 = self.eta * grad1, self.eta * grad2\n",
    "                self.W1 -= (delta_W1 + (self.alpha * delta_W1_prev))\n",
    "                self.W2 -= (delta_W2 + (self.alpha * delta_W2_prev))\n",
    "                delta_W1_prev, delta_W2_prev = delta_W1, delta_W2\n",
    "\n",
    "            self.cost_.append(mini_cost)\n",
    "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "            \n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to implement the new style of objective function, \n",
    "# we just need to update the final layer calculation of the gradient\n",
    "class TLPMiniBatchCrossEntropy(TLPMiniBatch):\n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = -np.mean(np.nan_to_num((Y_enc*np.log(A3)+(1-Y_enc)*np.log(1-A3))))\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        sigma3 = (A3-Y_enc) # <- this is only line that changed\n",
    "        if self.nonlinear == 'sigmoid':\n",
    "            sigma2 = (W2.T @ sigma3)*A2*(1-A2)\n",
    "        elif self.nonlinear == 'linear':\n",
    "            sigma2 = (W2.T @ sigma3)\n",
    "        elif self.nonlinear == 'relu':\n",
    "            sigma2 = (W2.T @ sigma3) \n",
    "            Z1_with_bias = self._add_bias_unit(Z1,how='row')\n",
    "            sigma2[Z1_with_bias<=0] = 0\n",
    "        grad1 = sigma2[1:,:] @ A1\n",
    "        grad2 = sigma3 @ A2.T\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        grad1[:, 1:] += W1[:, 1:] * self.l2_C\n",
    "        grad2[:, 1:] += W2[:, 1:] * self.l2_C\n",
    "\n",
    "        return grad1, grad2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TLPWrapper(object):\n",
    "    def __init__(self, cost_func=\"quad\",**kwds):\n",
    "        self.cost_func = cost_func    #quad or cross_ent\n",
    "        if self.cost_func == \"cross_ent\":\n",
    "            self.neural = TLPMiniBatchCrossEntropy(**kwds)\n",
    "        elif self.cost_func == \"quad\":\n",
    "            self.neural = TLPMiniBatch(**kwds)\n",
    "        else:\n",
    "            print(\"Invalid cost function chosen. Pick either 'quad' or 'cross_ent'\")\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.neural.fit(x_train, y_train)\n",
    "    def predict(self, x_test):\n",
    "        return self.neural.predict(x_test)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyper-Parameters\n",
    "Below we will tune hyperparamters for our MLP in an attempt to get our model as reliable as possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Number of Neurons\n",
    "Below we attempt to tune the amount of neurons in the hidden layer as a hyper-parameter. We range from 10 to 90 stepping up 10 neurons each time. We fit the MLP model to 10 different cross-validated training sets appending the resultant confusion matrix multiplied out by our cost matrix (described in the \"Evaluation\" section) into a list. This list is then fed into a boxplot which is displayed below. In doing this we hope to find which amount of hidden layer neurons makes for the best MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Tuning hidden neurons\n",
    "hidden_confusion_list = []\n",
    "neuron_list = []\n",
    "for x in range(10, 100, 10):\n",
    "    neuron_list.append(x)\n",
    "    cross_ent_confusion = []\n",
    "    vals = {'n_hidden': x, \n",
    "             'C':0.0, 'epochs':50, 'eta':0.001, \n",
    "             'alpha':0.0, 'decrease_const':1e-5, 'minibatches':128,\n",
    "            'shuffle':True,'random_state':1, 'nonlinear': 'sigmoid'}\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "\n",
    "        X_train = X[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        cross_ent_nn = TLPWrapper(cost_func=\"cross_ent\", **vals)\n",
    "\n",
    "        cross_ent_nn.fit(X_train, y_train)\n",
    "\n",
    "        yhat = cross_ent_nn.predict(X_test)\n",
    "        cross_ent_confusion.append(confusion_matrix(y_test, yhat)*cost_matrix)\n",
    "\n",
    "    hidden_confusion_list.append(cross_ent_confusion)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZCAiIigZiIgISgYiIgL8f60Q0hKvQ3M9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21b32566c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medians of Neuron Sets: \n",
      "40.0\n",
      "41.0\n",
      "28.0\n",
      "34.0\n",
      "28.0\n",
      "40.0\n",
      "38.0\n",
      "41.0\n",
      "36.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.boxplot(hidden_confusion_list, labels=neuron_list)\n",
    "plt.show()\n",
    "\n",
    "print(\"Medians of Neuron Sets: \")\n",
    "for cost_conf in hidden_confusion_list:\n",
    "    print(np.median(cost_conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the boxplot and numerical list of medians above you can see the variation in cost score per set of neurons. While there are not huge variations in the medians between all of these options, the MLP produced with 50 neurons has as low a median as the set with 30, but has fewer extreme outliers. For these reasons we find that our implementation of the MLP is best with 50 neurons. This is used below when we compare to the scikit-leanr implementation of an MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning using Various Nonlinearities\n",
    "Below we attempt to find the best nonlinearity for our implementation of MLP. We run linear, sigmoid, and relu through 10 different cross validated datasets and append it onto a list which is displayed in the boxplot below. We also show the medians numerically. With this we hope to find the most effective nonlinearity for our implementation of MLP. We will compare this to scikit-learn later in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:6: RuntimeWarning: invalid value encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Tuning nonlinearity function\n",
    "nonlinear_confusion_list = []\n",
    "nonlinear_list = ['linear', 'sigmoid', 'relu']\n",
    "for x in nonlinear_list:\n",
    "    cross_ent_confusion = []\n",
    "    vals = {'n_hidden': 100, \n",
    "             'C':0.0, 'epochs':50, 'eta':0.001, \n",
    "             'alpha':0.0, 'decrease_const':1e-5, 'minibatches':128,\n",
    "            'shuffle':True,'random_state':1, 'nonlinear': x}\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "\n",
    "        X_train = X[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        cross_ent_nn = TLPWrapper(cost_func=\"cross_ent\", **vals)\n",
    "\n",
    "        cross_ent_nn.fit(X_train, y_train)\n",
    "\n",
    "        yhat = cross_ent_nn.predict(X_test)\n",
    "        cross_ent_confusion.append(confusion_matrix(y_test, yhat) * cost_matrix)\n",
    "\n",
    "    nonlinear_confusion_list.append(cross_ent_confusion)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21b32626128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of linear:  28.0\n",
      "Median of sigmoid:  35.0\n",
      "Median of reul:  20.0\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.boxplot(nonlinear_confusion_list, labels=nonlinear_list)\n",
    "plt.show()\n",
    "\n",
    "print(\"Median of linear: \", np.median(nonlinear_confusion_list[0]))\n",
    "print(\"Median of sigmoid: \", np.median(nonlinear_confusion_list[1]))\n",
    "print(\"Median of reul: \", np.median(nonlinear_confusion_list[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see that relu performed significantly better than linear and sigmoid. Its median was a full 8 points lower than that of linear and 15 points lower than sigmoid. Its top whisker and outliers are all lower down than the other two methods. Because of these things we believe that relu is the best nonlinearity for our implementation of MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Custom MLP to scikit-learn\n",
    "Here we compare scikit-learn's MLP model to our custom implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-Learn\n",
    "Below we have the implementation from scikit-learn. We also run this on the same cross-validated data. Later we compare the result to our top custom implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21b322075f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "sk_confusion = []\n",
    "sk_confusion_compare = []\n",
    "clf = MLPClassifier(hidden_layer_sizes=(50, ), \n",
    "                    activation='relu', # type of non-linearity, every layer\n",
    "                    solver='sgd', \n",
    "                    alpha=1e-4, # L2 penalty\n",
    "                    batch_size= 'auto', # min of 200, num_samples\n",
    "                    learning_rate='constant', # adapt learning? only for sgd\n",
    "                    learning_rate_init=0.1, # only SGD\n",
    "                    power_t=0.0,    # only SGD with inverse scaling of learning rate\n",
    "                    max_iter=75, # stopping criteria\n",
    "                    shuffle=True, \n",
    "                    random_state=1, \n",
    "                    tol=0, # for stopping\n",
    "                    verbose=False, \n",
    "                    warm_start=False, \n",
    "                    momentum=0.9, # only SGD\n",
    "                    nesterovs_momentum=False, # only SGD\n",
    "                    early_stopping=False, \n",
    "                    validation_fraction=0.0, # only if early_stop is true\n",
    "                    beta_1=0.9, # adam decay rate of moment\n",
    "                    beta_2=0.999, # adam decay rate of moment\n",
    "                    epsilon=1e-08) # adam numerical stabilizer\n",
    "\n",
    "def run_scikit(X, y):\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train,y_train)\n",
    "        yhat = clf.predict(X_test)\n",
    "        sk_confusion.append(confusion_matrix(y_test, yhat) * cost_matrix) \n",
    "    sk_confusion_compare.append(sk_confusion)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "mem_scikit = memory_usage((run_scikit, (X, y)))  \n",
    "stop = timeit.default_timer()\n",
    "time_scikit = stop - start\n",
    "\n",
    "plt.figure()\n",
    "plt.boxplot(sk_confusion)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the boxplot above you can see the variation in performance with the variation in the cross-validated splits. Let's combine all of those together to get one boxplot of the performance to compare to our implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21b3264cbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of Scikit:  22.0\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.boxplot(sk_confusion_compare, labels=[\"Scikit MLP\"])\n",
    "plt.show()\n",
    "\n",
    "print(\"Median of Scikit: \", np.median(sk_confusion_compare))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Best Shot\n",
    "Wow! That was a pretty good try from scikit-learn. Now we will attempt our best implementation as we determined in the parameter-tuning section above. We use relu as the nonlinearity and a set of 50 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Tuning nonlinearity function\n",
    "nonlinear_confusion = []\n",
    "cross_ent_confusion = []\n",
    "vals = {'n_hidden': 50, \n",
    "         'C':0.0, 'epochs':50, 'eta':0.001, \n",
    "         'alpha':0.0, 'decrease_const':1e-5, 'minibatches':128,\n",
    "        'shuffle':True,'random_state':1, 'nonlinear': 'relu'}\n",
    "\n",
    "def run_custom(X, y):\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train = X[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        cross_ent_nn = TLPWrapper(cost_func=\"cross_ent\", **vals)\n",
    "\n",
    "        cross_ent_nn.fit(X_train, y_train)\n",
    "\n",
    "        yhat = cross_ent_nn.predict(X_test)\n",
    "        cross_ent_confusion.append(confusion_matrix(y_test, yhat) * cost_matrix)\n",
    "\n",
    "    nonlinear_confusion.append(cross_ent_confusion)\n",
    "    \n",
    "start = timeit.default_timer()\n",
    "mem_custom = memory_usage((run_custom, (X, y)))  \n",
    "stop = timeit.default_timer()\n",
    "time_custom = stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYRhIkjAMJEkYBpIk4P8DHoN1yQcMq9cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21b326737f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of linear:  20.0\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.boxplot(nonlinear_confusion, labels=[\"Custom Implementation\"])\n",
    "plt.show()\n",
    "\n",
    "print(\"Median of linear: \", np.median(nonlinear_confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good! We get pretty good performance out of this one! Now let's comapre the performance of both side by side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Final Showdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzMD/j+Wkmj1tsefbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21b324aecf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of Scikit:  22.0\n",
      "Mean of scikit 50.45\n",
      "Median of custom:  20.0\n",
      "Mean of custom: 49.50625\n"
     ]
    }
   ],
   "source": [
    "showdown_list = [sk_confusion_compare, nonlinear_confusion]\n",
    "\n",
    "plt.figure()\n",
    "plt.boxplot(showdown_list, labels=[\"Scikit-learn\", \"Custom Implementation\"])\n",
    "plt.show()\n",
    "\n",
    "print(\"Median of Scikit: \", np.median(sk_confusion_compare))\n",
    "print(\"Mean of scikit\", np.mean(sk_confusion_compare))\n",
    "print(\"Median of custom: \", np.median(nonlinear_confusion))\n",
    "print(\"Mean of custom:\", np.mean(nonlinear_confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for scikit: 2.4481864281988237 seconds\n",
      "time for custom: 21.085745845542988 seconds\n",
      "memory for scikit: 113.875 MB\n",
      "memory for custom 114.2421875 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"time for scikit:\", time_scikit, \"seconds\")\n",
    "print(\"time for custom:\", time_custom, \"seconds\")\n",
    "print(\"memory for scikit:\", mem_scikit[0], \"MB\")\n",
    "print(\"memory for custom\", mem_custom[0], \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it looks like our custom built MLP does actually perform better than the tried-and-true scikit-learn implementation! Since ours has a lower median, a lower mean, a lower third quartile, a lower top whisker, and lower outliers it is safe to say that our implementation truly has better generalization performance! However the standard scikit MLP model training took much less time than it took to train our custom MLP, by a factor of about 10. This is no surprise since scikit is written in C++ under the hood, and our model contains many for loops and if statements to slow it down. However, the memory usage of the two turns out to be more or less the same. \n",
    "\n",
    "All in all it is safe to say that the two implementations fare about the same. Ours has better performance, but their's is faster. It would depend on the application for which one we would want to employ! But either way our implementation was a success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work\n",
    "**NB** Our exceptional work is implementing relu and using it to improve the performance of our model. We found that using relu as our nonlinearity was, in fact, a good decision because it did produce the most performant model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
