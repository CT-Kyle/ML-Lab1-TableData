{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rage Against the Machine Learning: Predicting the Next Hollywood Hit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Preparation and Overview (30 points total)*\n",
    "**Requirement: **[5 points] Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). Detail exactly what the classification task is and what parties would be interested in the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of our Efforts\n",
    "There are literally tens of thousands of movies out there today. While some do great at the box office and bring in a lot of money, others flop making only a fraction of the top hits. What if we had a scientific way of accurately predicting how much revenue a movie would generate over its lifetime? Well, through machine learning we believe that we actually can!\n",
    "\n",
    "The dataset we are using is found on <a href=\"https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset\">Kaggle</a>. It consists of 5000+ movies scraped from the review site IMDB. There is quite a bit of data recorded for each movie and so we had a lot to work with to try to predict the next big hit. The data was collected from web scraping IMDB using a python library called \"scrappy\" to collect all of the data below. The features recorded for each movie are: \n",
    "\n",
    "Basic Info:\n",
    "- movie title\n",
    "- color (black and white or color)\t\n",
    "- duration of the movie\n",
    "- director name\n",
    "- gross (total revenue)\n",
    "- genres (a lits of different genres ascribed to the movie)\n",
    "- number of faces in movie poster\n",
    "- language of the movie\n",
    "- country the movie was produced in\n",
    "- content rating (G, PG, PG-13, R, NC-17)\n",
    "- budget\n",
    "- year of release\n",
    "- aspect ratio\n",
    "- name of the 3rd actor\n",
    "- name of the 2nd actor\n",
    "- name of the 1st actor\n",
    "\n",
    "Facebook Info:\n",
    "- number of director facebook likes\n",
    "- number of facebook likes for the whole cast\n",
    "- number of the movie's facebook likes\n",
    "- number of the 3rd actor's facebook likes\n",
    "- number of the 2nd actor's facebook likes\n",
    "- number of the 1st actor's facebook likes\n",
    "\n",
    "IMDB Specific Info:\n",
    "- number of imdb users who rated the movie\n",
    "- number of critical reviews for the movie\n",
    "- number of users who left a review\n",
    "- imdb score\n",
    "- top plot keywords\n",
    "\n",
    "\n",
    "With all of this data collected on so many movies, we hope to be able to use this to build out a linear regression model to accurately predict the financial success (measured in gross revenue) of a movie. We think that this could be a useful tool to anyone in the movie industry who is concerned with making a profit on their movie. It could also help a producer understand which of these features are the most important to an accurate prediction, what actors have been successful, what directors have been successful, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirement: ** [10 points] (mostly the same processes as from lab one) Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Mangling:\n",
    "\n",
    "Mangling of the CSV:\n",
    "- We first removed the imdb link from the csv because we knew we would never need to use that (**Note: this was the only feature removed from the csv**)\n",
    "- We then went through and deleted all of the movies that were made in another country (foriegn films) we did this because we wanted to just look at American films, also because the currency units for those countries (for budget and gross) were in native currency units, not USD, and with changing exchange rates, it's not very easy to compare across countries.\n",
    "- We then went through and converted all 0 values for gross, movie_facebook_likes, and director_facebook_likes to a blank value in the csv (so that it is read in as NaN by pandas), this is so that we cna more easily impute values later. Note: according to the description on the kaggle entry, because of the way the data was scraped, some movies had missing data. The Python scraper just made these values into a 0 instead of NaN.\n",
    "- We then removed all movies with an undefined gross. Being the feature we are trying to predict, we should not be imputing values for gross to train our model. That will basically reduce our model to an imputation algorithm...\n",
    "- We then removed all movies that were made before 1935. We did this because there were only a handful of movies ranging from 1915 to 1935, the way we are classifying budget (described below) would not work with a small sample of movies from that time period. We could have cut this number at a different year (say 1960), but we didn't want to exclude such classics as \"Bambi\" or \"Gone With the Wind\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mangling of the Data:\n",
    "- After the above steps, we made more edits to the data using pandas. First, we removed features that we thought would be un-useful to our prediction algorithm. We removed all features concerning facebook likes. We did this because a significant portion of the movies in the training set debuted before facebook was invented and widely adopted. While some of these movies have received retroactive \"likes\" on facebook, only the most famous classics received a substantial amount of retraoctive \"likes\". Most lesser known films received very low amounts of \"likes\" (presumably because modern movie watchers don't really care to search for lesser known movies on facebook, or because the movie doesn't have a facebook). For this reason we decided to remove movie_facebook_likes\n",
    "- Likewise, we removed the other \"likes\" for the same reasons as above. For example, the esteemed director George Lucas has a total of 0 \"likes\" between all of his films. This feature obviously would not help us predict the profitability of movies.\n",
    "- We also removed irrelevant information such as aspect_ratio, language, and country. Because we deleted all foreign films the country will always be USA. A simple filter of the data reveals that there are no more than 20 movies made in the US that use a language other than English, therefore there is not enough data to use language as training feature. However, we did not delete the movies in a different language, because most of them were famous films such as *Letters from Iwo Jima* and *The Kite Runner*. We still count them as a valuable part of the dataset, just don't find the language of particular value. Lastly, we removed aspect_ratio because that seems to be unimportant for predicting the success of a movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need all of this here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12222010206011191\n",
      "45.73046875\n"
     ]
    }
   ],
   "source": [
    "%reload_ext memory_profiler\n",
    "import timeit\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# def f(a, n=100):\n",
    "#     import time\n",
    "#     time.sleep(6)\n",
    "#     return 1\n",
    "# mem = memory_usage((f, (1,), {'n' : int(1e6)}))\n",
    "\n",
    "time = timeit.timeit((f, (1,), {'n' : int(1e6)}))\n",
    "time = timeit.timeit('char in text', setup='text = \"sample string\"; char = \"g\"')\n",
    "print(time)\n",
    "print(mem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3222 entries, 0 to 3221\n",
      "Data columns (total 12 columns):\n",
      "director_name             3222 non-null object\n",
      "num_critic_for_reviews    3219 non-null float64\n",
      "duration                  3221 non-null float64\n",
      "gross                     3222 non-null int64\n",
      "actor_1_name              3220 non-null object\n",
      "num_voted_users           3222 non-null int64\n",
      "facenumber_in_poster      3216 non-null float64\n",
      "num_user_for_reviews      3221 non-null float64\n",
      "content_rating            3196 non-null object\n",
      "budget                    3062 non-null float64\n",
      "title_year                3222 non-null int64\n",
      "imdb_score                3222 non-null float64\n",
      "dtypes: float64(6), int64(3), object(3)\n",
      "memory usage: 302.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"movie_data_trim.csv\")\n",
    "for x in ['movie_facebook_likes', 'director_facebook_likes', 'actor_2_facebook_likes', \n",
    "          'actor_1_facebook_likes','actor_3_facebook_likes', 'cast_total_facebook_likes',\n",
    "          'aspect_ratio', 'language', 'country', 'plot_keywords', 'actor_3_name', 'actor_2_name', 'movie_title', 'genres', 'color']:\n",
    "    if x in df:\n",
    "        del df[x]\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting for Inflation\n",
    "We need to adjust for inflation before we impute any of the values. For adjusting for inflation we obtained a csv of consumer price index (CPI) for every month since 1947. To simplify, we just took the value for January of that year to use for the whole year. We then took the CPI and calculated the ratio per year compared to 2017 dollars. This is shown below to give a sense of what inflation has looked like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DATE   VALUE\n",
      "0  1947  11.367\n",
      "1  1948  10.311\n",
      "2  1949  10.169\n",
      "3  1950  10.385\n",
      "4  1951   9.620\n",
      "5  1952   9.231\n",
      "6  1953   9.165\n",
      "7  1954   9.063\n",
      "8  1955   9.121\n",
      "9  1956   9.100\n"
     ]
    }
   ],
   "source": [
    "df_inflation = pd.read_csv(\"inflation_data.csv\")\n",
    "print(df_inflation[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then take the budget and gross and multiply them out with their appropriate ratio value. In this way everything is converted to 2017 dollars USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for x in range(0, len(df)):\n",
    "    adjusted = list(np.where(df_inflation[\"DATE\"] == df['title_year'][x])[0])\n",
    "    adjusted = df_inflation.iloc[adjusted]['VALUE'].values[0]\n",
    "    df['gross'][x] = df['gross'][x] * adjusted \n",
    "    df['budget'][x] = df['budget'][x] * adjusted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ings to improve imputations? How do we improve how many values get imputed?\n",
    "df_grouped = df.groupby(by=['director_name'])\n",
    "# director_name adds about 50 rows (imputes about 50 rows and then deletes about 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3127 entries, 0 to 3220\n",
      "Data columns (total 12 columns):\n",
      "num_critic_for_reviews    3127 non-null float64\n",
      "duration                  3127 non-null float64\n",
      "gross                     3127 non-null int64\n",
      "num_voted_users           3127 non-null int64\n",
      "facenumber_in_poster      3127 non-null float64\n",
      "num_user_for_reviews      3127 non-null float64\n",
      "budget                    3127 non-null float64\n",
      "title_year                3127 non-null int64\n",
      "imdb_score                3127 non-null float64\n",
      "director_name             3127 non-null object\n",
      "actor_1_name              3127 non-null object\n",
      "content_rating            3127 non-null object\n",
      "dtypes: float64(6), int64(3), object(3)\n",
      "memory usage: 317.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_imputed = df_grouped.transform(lambda grp: grp.fillna(grp.median()))\n",
    "col_deleted = list( set(df.columns) - set(df_imputed.columns)) #in case the median op deleted columns\n",
    "df_imputed[col_deleted] = df[col_deleted]\n",
    "\n",
    "# drop rows that still have missing values after imputation\n",
    "df_imputed.dropna(inplace=True)\n",
    "print(df_imputed.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df:  (3127, 12)\n",
      "(3127, 18)\n",
      "Wall time: 3.54 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#scaling budgets!\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "\n",
    "\n",
    "budget = df_imputed['budget'].values.reshape(-1, 1)\n",
    "df_imputed.reset_index(drop=True, inplace=True)\n",
    "print(\"df: \",df_imputed.shape)\n",
    "\n",
    "append_list = [df_imputed]\n",
    "\n",
    "budget_scaler = StandardScaler()\n",
    "append_list.append(pd.DataFrame(budget_scaler.fit_transform(budget), columns=['scaled_budget']))\n",
    "\n",
    "gross = df_imputed['gross'].values.reshape(-1,1)\n",
    "gross_scaler = StandardScaler()\n",
    "append_list.append(pd.DataFrame(gross_scaler.fit_transform(gross), columns=['scaled_gross']))\n",
    "\n",
    "critics = df_imputed['num_critic_for_reviews'].values.reshape(-1, 1)\n",
    "critic_scaler = StandardScaler()\n",
    "append_list.append(pd.DataFrame(critic_scaler.fit_transform(critics), columns=['scaled_critics']))\n",
    "# print(df)\n",
    "\n",
    "duration = df_imputed['duration'].values.reshape(-1, 1)\n",
    "duration_scaler = StandardScaler()\n",
    "append_list.append(pd.DataFrame(duration_scaler.fit_transform(duration), columns=['scaled_duration']))\n",
    "         \n",
    "num_voted_users = df_imputed['num_voted_users'].values.reshape(-1, 1)\n",
    "voted_scaler = StandardScaler()\n",
    "append_list.append(pd.DataFrame(voted_scaler.fit_transform(num_voted_users), columns=['scaled_voted_users']))\n",
    "\n",
    "num_user_for_reviews = df_imputed['num_user_for_reviews'].values.reshape(-1,1)\n",
    "user_reviews_scaler = StandardScaler()\n",
    "append_list.append(pd.DataFrame(user_reviews_scaler.fit_transform(num_user_for_reviews), columns=['scaled_user_reviews']))\n",
    "\n",
    "df = pd.concat(append_list, axis=1)\n",
    "\n",
    "#one-hot encode\n",
    "# hot_director = pd.get_dummies(df_imputed.director_name, prefix='directorName')\n",
    "hot_content = pd.get_dummies(df_imputed.content_rating, prefix='contentRating')\n",
    "# hot_actor = pd.get_dummies(df_imputed.actor_1_name, prefix='actorName')\n",
    "# df = pd.concat([df, hot_director, hot_content, hot_actor], axis=1)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting the gross into categories\n",
    "- add another label if I want to! And talk about it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "spacing = np.linspace(0, max(df['gross']), 100)\n",
    "labels = []\n",
    "\n",
    "labels = [\"low\", \"low-mid\", \"high-mid\", \"high\"]\n",
    "df['gross_group'] = pd.qcut(df['gross'], 4, labels=labels)\n",
    "\n",
    "\n",
    "rating_group = df['gross_group'].values\n",
    "rating_encoder = LabelEncoder()\n",
    "rating_df = pd.DataFrame(rating_encoder.fit_transform(rating_group), columns=['encoded_gross']).astype(str)\n",
    "df = pd.concat([df, rating_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirement: ** [15 points] Divide you data into training and testing data using an 80% training and 20% testing split. Use the cross validation modules that are part of scikit-learn. Argue for or against splitting your data using an 80/20 split. That is, why is the 80/20 split appropriate (or not) for your dataset?  \n",
    "\n",
    "### Split Up the Data Now\n",
    "\n",
    "Below we split up the data into testing and training sets. We use the train_test_split function from sklearn to achieve splittling and cross validation of the data set. In this way we have an averaged training and testing set to use for our model. We decided to use an 80/20 split (that is, 80% of the set is used for training, 20% is used for testing), as that seemed to be the best breakdown for our data as mentioned through several <a href=\"http://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio\">stack overflow posts</a>.\n",
    "\n",
    "We want to balance the tradeoffs between having a smaller training set and having a smaller testing set. With less training data we risk having greater variance in our parameter estimates, with less testing data we will have a greater variance in our performance statistics. The best case is to balance the effects of both, by running a few different splits and seeing what variance we get on different splits. It seemed that the 80/20 split was the best option for our dataset and gave us the least variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2501 626\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "train_set, test_set = model_selection.train_test_split(df, test_size=0.2, train_size=0.8, random_state= 101)\n",
    "print(len(train_set), len(test_set))\n",
    "## http://localhost:8888/notebooks/fork/MachineLearningNotebooks/05.%20Logistic%20Regression.ipynb#Training-and-Testing-Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Modeling (50 points total)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# But First... A Super Cool Custom Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirement**: [20 points] Create a custom, one-versus-all logistic regression classifier using numpy and scipy to optimize. Use object oriented conventions identical to scikit-learn. You should start with the template used in the course. You should add the following functionality to the logistic regression classifier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirement: ** Update the gradient calculation to include a customizable regularization term (either using no regularization, L1 regularization, L2 regularization, or both L1/L2 norm of the weights). Associate a cost with the regularization term, \"C\", that can be adjusted when the class is instantiated.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.special import expit\n",
    "\n",
    "def regularize(regularization, gradient, w, C):\n",
    "    if(regularization == 'l2'):\n",
    "        gradient[1:] += -2 * w[1:] * C\n",
    "    elif(regularization == 'l1'):\n",
    "        gradient[1:] += np.sign(w[1:]) * C\n",
    "    elif(regularization =='l1/l2'):\n",
    "        gradient[1:] += -2 * w[1:] * C\n",
    "        gradient[1:] += np.sign(w[1:]) * C\n",
    "\n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from last time, our logistic regression algorithm is given by (including everything we previously had):\n",
    "class BinaryLogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.001, regularization='none'):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        self.reg = regularization\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "        \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    # convenience, private:\n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # vectorized gradient calculation with regularization using L2 Norm\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        \n",
    "        gradient = regularize(self.reg, gradient, self.w_, self.C)\n",
    "#         gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self,X,add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class StochasticBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # stochastic gradient calculation \n",
    "    def _get_gradient(self,X,y):\n",
    "        idx = int(np.random.rand()*len(y)) # grab random instance\n",
    "        ydiff = y[idx]-self.predict_proba(X[idx],add_bias=False) # get y difference (now scalar)\n",
    "        gradient = X[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "#         gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        regularize(self.reg, gradient, self.w_, self.C)\n",
    "        \n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import pinv\n",
    "class HessianBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # just overwrite gradient function\n",
    "    def _get_gradient(self,X,y):\n",
    "        g = self.predict_proba(X,add_bias=False).ravel() # get sigmoid value for all classes\n",
    "        hessian = X.T @ np.diag(g*(1-g)) @ X - 2 * self.C # calculate the hessian\n",
    "\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.sum(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient = regularize(self.reg, gradient, self.w_, self.C)\n",
    "#         gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return pinv(hessian) @ gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_bfgs\n",
    "class BFGSBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    \n",
    "    @staticmethod\n",
    "    def objective_function(w,X,y,C,reg):\n",
    "        g = expit(X @ w)\n",
    "        return -np.sum(np.log(g[y==1]))-np.sum(np.log(1-g[y==0])) + C*sum(w**2) #-np.sum(y*np.log(g)+(1-y)*np.log(1-g))\n",
    "\n",
    "    @staticmethod\n",
    "    def objective_gradient(w,X,y,C,reg):\n",
    "        g = expit(X @ w)\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0)\n",
    "        gradient = gradient.reshape(w.shape)\n",
    "        gradient = regularize(reg, gradient, w, C)\n",
    "        return -gradient\n",
    "    \n",
    "    # just overwrite fit function\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = fmin_bfgs(self.objective_function, # what to optimize\n",
    "                            np.zeros((num_features,1)), # starting point\n",
    "                            fprime=self.objective_gradient, # gradient function\n",
    "                            args=(Xb,y,self.C, self.reg), # extra args for gradient and objective function\n",
    "                            gtol=1e-03, # stopping criteria for gradient, |v_k|\n",
    "                            maxiter=self.iters, # stopping criteria iterations\n",
    "                            disp=False)\n",
    "        \n",
    "        self.w_ = self.w_.reshape((num_features,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.001, optimizer=\"steep_desc\", regularization=\"none\"):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        self.optimizer = optimizer\n",
    "        self.reg = regularization  \n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.sort(np.unique(y)) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = []\n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            if self.optimizer == \"steep_desc\":\n",
    "                blr = BinaryLogisticRegression(self.eta, self.iters, self.C, self.reg) #??\n",
    "            elif self.optimizer == \"stoch_grad\":\n",
    "                blr = StochasticBinaryLogisticRegression(self.eta, self.iters, self.C, self.reg)\n",
    "            elif self.optimizer == \"hessian\":\n",
    "                blr = HessianBinaryLogisticRegression(self.eta, self.iters, self.C, self.reg)\n",
    "            elif self.optimizer == \"bfgs\":\n",
    "                blr = BFGSBinaryLogisticRegression(self.eta, self.iters, self.C, self.reg)\n",
    "                \n",
    "            y_binary = y==yval # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr.fit(X,y_binary)\n",
    "            #print(accuracy(y_binary,bin_class.predict(X)))\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T    \n",
    "       \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier  ##go through the list of classifiers and get predictions for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_proba(X),axis=1) # take argmax along row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "**Requirement**: Ability to choose optimization technique when class is instantiated: either steepest descent, stochastic gradient descent, or Newton's method (also BFGS). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Logistic Regression Object with coefficients:\n",
      "[[-0.31651999]\n",
      " [-0.32616006]\n",
      " [-1.35771834]\n",
      " [ 2.77188848]\n",
      " [ 1.38343114]]\n",
      "Accuracy of:  0.666666666667\n",
      "--------------------\n",
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[ 0.36842154  0.47783978  1.65793412 -2.65476947 -1.2084986 ]\n",
      " [ 0.98954301  0.47600051 -2.90588154  0.49849588 -1.91198992]\n",
      " [-1.63414541 -2.6944199  -2.56140081  4.20146255  3.47282559]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Accuracy of:  0.68\n",
      "Wall time: 357 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Linear Regression Testing\n",
    "ds = load_iris()\n",
    "X = ds.data\n",
    "y = ds.target # note problem is NOT binary anymore, there are three classes!\n",
    "# y = (ds.target>1).astype(np.int) # make problem binary\n",
    "\n",
    "blr = BFGSBinaryLogisticRegression(0.1, 1000, C=.001, regularization='l2')\n",
    "blr.fit(X,y)\n",
    "print(blr)\n",
    "yhat = blr.predict(X)\n",
    "print('Accuracy of: ',accuracy_score(y,yhat)) \n",
    "\n",
    "print(\"--------------------\")\n",
    "\n",
    "lr = LogisticRegression(0.1, 1000, C=0.001, optimizer=\"stoch_grad\", regularization='l2')\n",
    "lr.fit(X,y)\n",
    "print(lr)\n",
    "yhat = lr.predict(X)\n",
    "\n",
    "print(y)\n",
    "print('Accuracy of: ',accuracy_score(y,yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "drop_list = ['scaled_gross', 'num_critic_for_reviews', 'encoded_gross', 'gross_group', \n",
    "              'gross', 'budget', 'director_name', 'actor_1_name', 'content_rating', 'duration',\n",
    "            'num_voted_users', 'num_user_for_reviews']\n",
    "# with one hot encoding\n",
    "X = train_set.drop(drop_list, axis=1)\n",
    "y = train_set['encoded_gross'].values\n",
    "X_test = test_set.drop(drop_list, axis=1)\n",
    "y_test = test_set['encoded_gross'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comapre this version of sklearn to our homegrown version of bfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    211\n",
      "0    184\n",
      "3    139\n",
      "1     92\n",
      "dtype: int64\n",
      "3    164\n",
      "1    157\n",
      "2    155\n",
      "0    150\n",
      "dtype: int64\n",
      "Accuracy of:  0.503194888179\n",
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression as sklr\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "lr_sk = sklr(solver='lbfgs') \n",
    "\n",
    "lr_sk.fit(X,y) # no need to add bias term, sklearn does it internally!!\n",
    "yhat = lr_sk.predict(X_test)\n",
    "print(pd.Series(yhat).value_counts())\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    164\n",
      "1    157\n",
      "2    155\n",
      "0    150\n",
      "dtype: int64\n",
      "0    626\n",
      "dtype: int64\n",
      "Accuracy of:  0.239616613419\n",
      "Wall time: 260 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clist = []\n",
    "tlr = LogisticRegression(0.1, 3000, C=.001, optimizer=\"stoch_grad\", regularization=\"l2\")\n",
    "# print(y)\n",
    "tlr.fit(X, y)\n",
    "# print(X)\n",
    "yhat = tlr.predict(X_test)\n",
    "print(pd.Series(y_test).value_counts())\n",
    "print(pd.Series(yhat).value_counts())\n",
    "print('Accuracy of: ',accuracy_score(y_test.astype(int),yhat.astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is our best method woo!! Compare this to scikit learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem: 109.01953125 MB\n",
      "time: 1.5408195071768205 seconds\n",
      "3    164\n",
      "1    157\n",
      "2    155\n",
      "0    150\n",
      "dtype: int64\n",
      "2    212\n",
      "0    178\n",
      "3    138\n",
      "1     98\n",
      "dtype: int64\n",
      "Accuracy of:  0.517571884984\n",
      "Wall time: 1.55 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clist = []\n",
    "tlr = LogisticRegression(0.1, 30, C=.001, optimizer=\"bfgs\", regularization=\"l1\")\n",
    "# print(y)\n",
    "# time = timeit.timeit('char in text', setup='text = \"sample string\"; char = \"g\"')\n",
    "\n",
    "start = timeit.default_timer()\n",
    "mem = memory_usage((tlr.fit, (X,y)))\n",
    "stop = timeit.default_timer()\n",
    "time = stop - start\n",
    "\n",
    "print(\"mem:\", mem[0], \"MB\")\n",
    "print(\"time:\", time, \"seconds\")\n",
    "\n",
    "yhat = tlr.predict(X_test)\n",
    "print(pd.Series(y_test).value_counts())\n",
    "print(pd.Series(yhat).value_counts())\n",
    "print('Accuracy of: ',accuracy_score(y_test.astype(int),yhat.astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the 4 methods! Graph these together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e59a5655d53b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msteep_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msteep_confusion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_values\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "## CHANGE THIS ALL TO STEEPEST DESCENT\n",
    "steep_list = []\n",
    "steep_confusion = []\n",
    "x_values = np.logspace(-3,1, num=25)\n",
    "x_values.sort()\n",
    "for i in x_values:\n",
    "    tlr = LogisticRegression(0.1, 1000, C=i, optimizer=\"steep_desc\", regularization=\"l2\")\n",
    "\n",
    "    tlr.fit(X, y)\n",
    "    yhat = tlr.predict(X)\n",
    "    steep_confusion.append(mt.confusion_matrix(y.astype(int), yhat.astype(int)))\n",
    "    steep_list.append(accuracy_score(y.astype(int),yhat.astype(int)))\n",
    "#     print('Accuracy of: ',accuracy_score(y,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stoch_list = []\n",
    "stoch_confusion = []\n",
    "x_values = np.logspace(-3,1, num=25)\n",
    "x_values.sort()\n",
    "for i in x_values:\n",
    "    tlr = LogisticRegression(0.1, 2000, C=i, optimizer=\"stoch_grad\", regularization=\"l2\")\n",
    "\n",
    "    # print(y)\n",
    "    tlr.fit(X, y)\n",
    "    yhat = tlr.predict(X)\n",
    "#     print(train_set.encoded_rating.value_counts())\n",
    "#     print(pd.Series(y).value_counts())\n",
    "#     print(pd.Series(yhat).value_counts())\n",
    "    stoch_confusion.append(mt.confusion_matrix(y.astype(int), yhat.astype(int)))\n",
    "    stoch_list.append(accuracy_score(y.astype(int),yhat.astype(int)))\n",
    "#     print('Accuracy of: ',accuracy_score(y,yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.89 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bfgs_list = []\n",
    "bfgs_confusion = []\n",
    "for i in x_values:\n",
    "    tlr = LogisticRegression(0.1, 50, C=i, optimizer=\"bfgs\", regularization=\"l2\")\n",
    "    tlr.fit(X, y)\n",
    "    yhat = tlr.predict(X)\n",
    "    #     print(train_set.encoded_rating.value_counts())\n",
    "#     print(pd.Series(y).value_counts())\n",
    "#     print(pd.Series(yhat).value_counts())\n",
    "#     print('Accuracy of: ',accuracy_score(y.astype(int),yhat.astype(int)))\n",
    "    bfgs_confusion.append(mt.confusion_matrix(y.astype(int), yhat.astype(int)))\n",
    "    bfgs_list.append(accuracy_score(y.astype(int),yhat.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hessian_list = []\n",
    "hessian_confusion = []\n",
    "for i in x_values:\n",
    "    tlr = LogisticRegression(0.1, 20, C=i, optimizer=\"hessian\", regularization=\"l2\")\n",
    "    tlr.fit(X, y)\n",
    "    yhat = tlr.predict(X)\n",
    "    #     print(train_set.encoded_rating.value_counts())\n",
    "#     print(pd.Series(y).value_counts())\n",
    "#     print(pd.Series(yhat).value_counts())\n",
    "#     print('Accuracy of: ',accuracy_score(y.astype(int),yhat.astype(int)))\n",
    "    hessian_confusion.append(mt.confusion_matrix(y.astype(int), yhat.astype(int)))\n",
    "    hessian_list.append(accuracy_score(y.astype(int),yhat.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hessian_confusion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-fda881050375>\u001b[0m in \u001b[0;36mlr_explor\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlr_explor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhessian_confusion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hessian_confusion' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets as wd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def lr_explor(val):\n",
    "    plt.imshow(hessian_confusion[val])\n",
    "    plt.colorbar()\n",
    "    \n",
    "wd.interact(lr_explor,val=(0,15,1),__manual=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX0Qkyij4RUSijIJfRCTKKPhFRKLM/wd1CnnDu3aNaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27180a6e0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ax=plt.subplot(111)\n",
    "# plt.plot(x_values, stoch_list, x_values, bfgs_list, x_values, hessian_list)\n",
    "plt.plot(x_values, bfgs_list)\n",
    "# plt.plot(x_values, hessian_list)\n",
    "ax.set_xscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirement: ** [15 points] Train your classifier to achieve good generalization performance. That is, adjust the optimization technique and the value of the regularization term \"C\" to achieve the best performance on your test set. Is your method of selecting parameters justified? That is, do you think there is any \"data snooping\" involved with this method of selecting parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization Performance, Optimizing \"C\", Data Snooping\n",
    "The generalization performance that we achieved was moderate. We got a reasonably accurate model trained! Above we have some graphs mapping the different \"C\" values to illustrate what C values were the best.\n",
    "\n",
    "There is definitely some \"data snooping\" going on in our dataset. Currently we are just splitting our data into training and testing sets. We end up \"snooping\" on the testing sets because we already know what they contain and can find accuracy based off of that. We can run the model on the testing data and use those results to tweak the values of C, gamma, and number of iterations (for each method). We tweak these parameters based on the accuracy that they yield. So we never have any true testing data to try out. If we wanted to improve upon our process, we would take a split of the original data as a holdout set and not look at that until we have a well trained model. We would then be able to test on that holdout data and get a fresh assessment of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirement: ** [15 points] Compare the performance of your \"best\" logistic regression optimization procedure to the procedure used in scikit-learn. Visualize the performance differences in terms of training time, training iterations, and memory usage while training. Discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Deployment (10 points total)*\n",
    "**Requirement: **Which implementation of logistic regression would you advise be used in a deployed machine learning model, your implementation or scikit-learn (or other third party)? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exceptional Work (10 points total)*\n",
    "**Rerquirement: ** You have free reign to provide additional analyses.\n",
    "One idea: Make your implementation of logistic regression compatible with the GridSearchCV function that is part of scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the grid search. bfgs will rock your socks off!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
