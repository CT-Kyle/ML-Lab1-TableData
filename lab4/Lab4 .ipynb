{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rage Against the Machine Learning: Predicting the Next Hollywood Hit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Preparation and Overview (30 points total)*\n",
    "**Requirement: **[5 points] Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). Detail exactly what the classification task is and what parties would be interested in the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of our Efforts\n",
    "There are literally tens of thousands of movies out there today. While some do great at the box office and bring in a lot of money, others flop making only a fraction of the top hits. What if we had a scientific way of accurately predicting how much revenue a movie would generate over its lifetime? Well, through machine learning we believe that we actually can!\n",
    "\n",
    "The dataset we are using is found on <a href=\"https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset\">Kaggle</a>. It consists of 5000+ movies scraped from the review site IMDB. There is quite a bit of data recorded for each movie and so we had a lot to work with to try to predict the next big hit. The data was collected from web scraping IMDB using a python library called \"scrappy\" to collect all of the data below. The features recorded for each movie are: \n",
    "\n",
    "Basic Info:\n",
    "- movie title\n",
    "- color (black and white or color)\t\n",
    "- duration of the movie\n",
    "- director name\n",
    "- gross (total revenue)\n",
    "- genres (a lits of different genres ascribed to the movie)\n",
    "- number of faces in movie poster\n",
    "- language of the movie\n",
    "- country the movie was produced in\n",
    "- content rating (G, PG, PG-13, R, NC-17)\n",
    "- budget\n",
    "- year of release\n",
    "- aspect ratio\n",
    "- name of the 3rd actor\n",
    "- name of the 2nd actor\n",
    "- name of the 1st actor\n",
    "\n",
    "Facebook Info:\n",
    "- number of director facebook likes\n",
    "- number of facebook likes for the whole cast\n",
    "- number of the movie's facebook likes\n",
    "- number of the 3rd actor's facebook likes\n",
    "- number of the 2nd actor's facebook likes\n",
    "- number of the 1st actor's facebook likes\n",
    "\n",
    "IMDB Specific Info:\n",
    "- number of imdb users who rated the movie\n",
    "- number of critical reviews for the movie\n",
    "- number of users who left a review\n",
    "- imdb score\n",
    "- top plot keywords\n",
    "\n",
    "\n",
    "With all of this data collected on so many movies, we hope to be able to use this to build out a linear regression model to accurately predict the financial success (measured in gross revenue) of a movie. We think that this could be a useful tool to anyone in the movie industry who is concerned with making a profit on their movie. It could also help a producer understand which of these features are the most important to an accurate prediction, what actors have been successful, what directors have been successful, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirement: ** [10 points] (mostly the same processes as from lab one) Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Mangling:\n",
    "\n",
    "Mangling of the CSV:\n",
    "- We first removed the imdb link from the csv because we knew we would never need to use that (**Note: this was the only feature removed from the csv**)\n",
    "- We then went through and deleted all of the movies that were made in another country (foriegn films) we did this because we wanted to just look at American films, also because the currency units for those countries (for budget and gross) were in native currency units, not USD, and with changing exchange rates, it's not very easy to compare across countries.\n",
    "- We then went through and converted all 0 values for gross, movie_facebook_likes, and director_facebook_likes to a blank value in the csv (so that it is read in as NaN by pandas), this is so that we cna more easily impute values later. Note: according to the description on the kaggle entry, because of the way the data was scraped, some movies had missing data. The Python scraper just made these values into a 0 instead of NaN.\n",
    "- We then removed all movies with an undefined gross. Being the feature we are trying to predict, we should not be imputing values for gross to train our model. That will basically reduce our model to an imputation algorithm...\n",
    "- We then removed all movies that were made before 1935. We did this because there were only a handful of movies ranging from 1915 to 1935, the way we are classifying budget (described below) would not work with a small sample of movies from that time period. We could have cut this number at a different year (say 1960), but we didn't want to exclude such classics as \"Bambi\" or \"Gone With the Wind\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mangling of the Data:\n",
    "- After the above steps, we made more edits to the data using pandas. First, we removed features that we thought would be un-useful to our prediction algorithm. We removed all features concerning facebook likes. We did this because a significant portion of the movies in the training set debuted before facebook was invented and widely adopted. While some of these movies have received retroactive \"likes\" on facebook, only the most famous classics received a substantial amount of retraoctive \"likes\". Most lesser known films received very low amounts of \"likes\" (presumably because modern movie watchers don't really care to search for lesser known movies on facebook, or because the movie doesn't have a facebook). For this reason we decided to remove movie_facebook_likes\n",
    "- Likewise, we removed the other \"likes\" for the same reasons as above. For example, the esteemed director George Lucas has a total of 0 \"likes\" between all of his films. This feature obviously would not help us predict the profitability of movies.\n",
    "- We also removed irrelevant information such as aspect_ratio, language, and country. Because we deleted all foreign films the country will always be USA. A simple filter of the data reveals that there are no more than 20 movies made in the US that use a language other than English, therefore there is not enough data to use language as training feature. However, we did not delete the movies in a different language, because most of them were famous films such as *Letters from Iwo Jima* and *The Kite Runner*. We still count them as a valuable part of the dataset, just don't find the language of particular value. Lastly, we removed aspect_ratio because that seems to be unimportant for predicting the success of a movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3222 entries, 0 to 3221\n",
      "Data columns (total 18 columns):\n",
      "color                     3221 non-null object\n",
      "director_name             3222 non-null object\n",
      "num_critic_for_reviews    3219 non-null float64\n",
      "duration                  3221 non-null float64\n",
      "actor_2_name              3219 non-null object\n",
      "gross                     3222 non-null int64\n",
      "genres                    3222 non-null object\n",
      "actor_1_name              3220 non-null object\n",
      "movie_title               3222 non-null object\n",
      "num_voted_users           3222 non-null int64\n",
      "actor_3_name              3216 non-null object\n",
      "facenumber_in_poster      3216 non-null float64\n",
      "plot_keywords             3198 non-null object\n",
      "num_user_for_reviews      3221 non-null float64\n",
      "content_rating            3196 non-null object\n",
      "budget                    3062 non-null float64\n",
      "title_year                3222 non-null int64\n",
      "imdb_score                3222 non-null float64\n",
      "dtypes: float64(6), int64(3), object(9)\n",
      "memory usage: 453.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"movie_data_trim.csv\")\n",
    "for x in ['movie_facebook_likes', 'director_facebook_likes', 'actor_2_facebook_likes', \n",
    "          'actor_1_facebook_likes','actor_3_facebook_likes', 'cast_total_facebook_likes',\n",
    "          'aspect_ratio', 'language', 'country']:\n",
    "    if x in df:\n",
    "        del df[x]\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting for Inflation\n",
    "We need to adjust for inflation before we impute any of the values. For adjusting for inflation we obtained a csv of consumer price index (CPI) for every month since 1947. To simplify, we just took the value for January of that year to use for the whole year. We then took the CPI and calculated the ratio per year compared to 2017 dollars. This is shown below to give a sense of what inflation has looked like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DATE   VALUE\n",
      "0  1947  11.367\n",
      "1  1948  10.311\n",
      "2  1949  10.169\n",
      "3  1950  10.385\n",
      "4  1951   9.620\n",
      "5  1952   9.231\n",
      "6  1953   9.165\n",
      "7  1954   9.063\n",
      "8  1955   9.121\n",
      "9  1956   9.100\n"
     ]
    }
   ],
   "source": [
    "df_inflation = pd.read_csv(\"inflation_data.csv\")\n",
    "print(df_inflation[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then take the budget and gross and multiply them out with their appropriate ratio value. In this way everything is converted to 2017 dollars USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramFiles\\lib\\site-packages\\ipykernel\\__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 color         director_name  num_critic_for_reviews  \\\n",
      "0      Black and White          Orson Welles                    90.0   \n",
      "1                Color     Vincente Minnelli                    41.0   \n",
      "2                Color         George Sidney                    21.0   \n",
      "3                Color      Cecil B. DeMille                    44.0   \n",
      "4                Color          Henry Koster                    42.0   \n",
      "5      Black and White         Eugène Lourié                    67.0   \n",
      "6      Black and White            Elia Kazan                   134.0   \n",
      "7      Black and White          Billy Wilder                   181.0   \n",
      "8      Black and White      Alfred Hitchcock                   290.0   \n",
      "9                Color        Jerome Robbins                   120.0   \n",
      "10               Color        Stanley Kramer                    61.0   \n",
      "11               Color          George Cukor                    82.0   \n",
      "12               Color      Robert Stevenson                   145.0   \n",
      "13     Black and White        Michael Roemer                    24.0   \n",
      "14               Color        George Stevens                    27.0   \n",
      "15               Color            David Lean                    89.0   \n",
      "16               Color           Robert Wise                   119.0   \n",
      "17               Color         Sam Peckinpah                    53.0   \n",
      "18               Color       George Roy Hill                   130.0   \n",
      "19               Color         Blake Edwards                    22.0   \n",
      "20               Color            Russ Meyer                   101.0   \n",
      "21               Color      Michael Wadleigh                    53.0   \n",
      "22               Color        Norman Jewison                    66.0   \n",
      "23               Color    Melvin Van Peebles                    38.0   \n",
      "24               Color         James Bidgood                     8.0   \n",
      "25               Color  Francis Ford Coppola                   208.0   \n",
      "26               Color           John Waters                    73.0   \n",
      "27               Color      William Friedkin                   304.0   \n",
      "28               Color       George Roy Hill                   119.0   \n",
      "29               Color          George Lucas                   100.0   \n",
      "...                ...                   ...                     ...   \n",
      "3192             Color             Gary Ross                    79.0   \n",
      "3193             Color             James Wan                   300.0   \n",
      "3194             Color             Tim Story                   119.0   \n",
      "3195             Color      Christian Ditter                   148.0   \n",
      "3196             Color            J Blakeson                   194.0   \n",
      "3197             Color      Nicholas Stoller                   177.0   \n",
      "3198             Color           Ben Falcone                   154.0   \n",
      "3199             Color           Burr Steers                   225.0   \n",
      "3200             Color          Jodie Foster                   268.0   \n",
      "3201             Color        Gavin O'Connor                   123.0   \n",
      "3202             Color             Jon Lucas                    81.0   \n",
      "3203             Color             Jon Lucas                    81.0   \n",
      "3204             Color        Kevin Reynolds                   122.0   \n",
      "3205             Color           Henry Joost                    86.0   \n",
      "3206             Color         John Hillcoat                   214.0   \n",
      "3207             Color       Cyrus Nowrasteh                    24.0   \n",
      "3208             Color            Kirk Jones                   156.0   \n",
      "3209             Color    Jaume Collet-Serra                   186.0   \n",
      "3210             Color      Dan Trachtenberg                   411.0   \n",
      "3211             Color         Peter Atencio                   129.0   \n",
      "3212             Color       Patricia Riggen                    63.0   \n",
      "3213             Color             Dan Mazer                   158.0   \n",
      "3214             Color    William Brent Bell                   159.0   \n",
      "3215             Color            Jason Zada                   185.0   \n",
      "3216             Color          Harold Cronk                    29.0   \n",
      "3217             Color        Michael Tiddes                    59.0   \n",
      "3218             Color        Bille Woodruff                    12.0   \n",
      "3219             Color     David F. Sandberg                   159.0   \n",
      "3220             Color       Craig Gillespie                   178.0   \n",
      "3221             Color         James Schamus                    63.0   \n",
      "\n",
      "      duration         actor_2_name       gross  \\\n",
      "0         92.0       Everett Sloane       90106   \n",
      "1        102.0        Reginald Owen    30479316   \n",
      "2        107.0          Howard Keel    83080000   \n",
      "3        152.0       Dorothy Lamour   332316000   \n",
      "4        135.0         Jean Simmons   329939999   \n",
      "5         80.0       Cecil Kellaway    45824999   \n",
      "6        108.0          Karl Malden    87004799   \n",
      "7        120.0         Joe E. Brown   210400000   \n",
      "8        108.0           Vera Miles   266015999   \n",
      "9        152.0      George Chakiris   357144300   \n",
      "10       197.0           Sid Caesar   371372300   \n",
      "11       170.0         Rex Harrison   568152000   \n",
      "12       139.0         Glynis Johns   807249300   \n",
      "13        95.0        Gloria Foster       98148   \n",
      "14       225.0        Carroll Baker    62448000   \n",
      "15       200.0         Klaus Kinski   872101932   \n",
      "16       174.0    Angela Cartwright  1274050716   \n",
      "17       152.0         Slim Pickens      116098   \n",
      "18       110.0          Ted Cassidy   699690567   \n",
      "19       143.0     Vernon Dobtcheff    32210000   \n",
      "20       109.0        Cynthia Myers    57978000   \n",
      "21       215.0         Jimi Hendrix    85678600   \n",
      "22       181.0  Paul Michael Glaser   305950000   \n",
      "23        97.0    Mario Van Peebles    92886420   \n",
      "24        65.0        Bobby Kendall       50365   \n",
      "25       175.0        Marlon Brando   798954887   \n",
      "26       108.0           Mink Stole     1069542   \n",
      "27       132.0          Linda Blair  1169702670   \n",
      "28       129.0          Robert Shaw   912592800   \n",
      "29       112.0           Ron Howard   657570000   \n",
      "...        ...                  ...         ...   \n",
      "3192     139.0       Donald Watkins    20899716   \n",
      "3193     134.0     Frances O'Connor   104867929   \n",
      "3194     102.0     Nadine Velazquez    93105905   \n",
      "3195     110.0     Damon Wayans Jr.    47983700   \n",
      "3196     112.0          Maggie Siff    35785806   \n",
      "3197      92.0       Ike Barinholtz    56674110   \n",
      "3198      99.0         Tyler Labine    64610623   \n",
      "3199     108.0      Bella Heathcote    11179973   \n",
      "3200      98.0       Jack O'Connell    42033745   \n",
      "3201      98.0        Noah Emmerich     1550635   \n",
      "3202     100.0        Jay Hernandez    56847839   \n",
      "3203     100.0        Jay Hernandez    56847839   \n",
      "3204     107.0           Jan Cornet    37796613   \n",
      "3205      96.0  Marc John Jefferies    29598847   \n",
      "3206     115.0        Norman Reedus    12942577   \n",
      "3207     111.0        Vincent Walsh     6624140   \n",
      "3208      94.0       Louis Mandylor    61062412   \n",
      "3209      86.0         Brett Cullen    55613868   \n",
      "3210     104.0   John Gallagher Jr.    73694645   \n",
      "3211     100.0           Will Forte    21080485   \n",
      "3212     109.0    Brighton Sharbino    63235861   \n",
      "3213     109.0          Zoey Deutch    36426003   \n",
      "3214      97.0         Rupert Evans    36689020   \n",
      "3215      93.0       Stephanie Vogt    27247953   \n",
      "3216     120.0         Robin Givens    21292396   \n",
      "3217      92.0            Mike Epps    11967057   \n",
      "3218      96.0       Brandy Norwood     9899829   \n",
      "3219      81.0         Amiah Miller    57949416   \n",
      "3220     117.0      Abraham Benrubi    28239503   \n",
      "3221     110.0          Sarah Gadon      574524   \n",
      "\n",
      "                                        genres           actor_1_name  \\\n",
      "0       Crime|Drama|Film-Noir|Mystery|Thriller          Rita Hayworth   \n",
      "1             Adventure|Comedy|Musical|Romance          Gladys Cooper   \n",
      "2     Biography|Comedy|Musical|Romance|Western            Keenan Wynn   \n",
      "3                         Drama|Family|Romance         Gloria Grahame   \n",
      "4                                Drama|History         Richard Burton   \n",
      "5                      Adventure|Horror|Sci-Fi          Kenneth Tobey   \n",
      "6                          Crime|Drama|Romance          Marlon Brando   \n",
      "7                         Comedy|Music|Romance       Nehemiah Persoff   \n",
      "8                      Horror|Mystery|Thriller            Janet Leigh   \n",
      "9         Crime|Drama|Musical|Romance|Thriller            Rita Moreno   \n",
      "10               Action|Adventure|Comedy|Crime       Jonathan Winters   \n",
      "11                Drama|Family|Musical|Romance           Jeremy Brett   \n",
      "12               Comedy|Family|Fantasy|Musical                Ed Wynn   \n",
      "13                               Drama|Romance           Yaphet Kotto   \n",
      "14                     Biography|Drama|History          Martin Landau   \n",
      "15                           Drama|Romance|War         Julie Christie   \n",
      "16      Biography|Drama|Family|Musical|Romance         Eleanor Parker   \n",
      "17                       Adventure|War|Western           James Coburn   \n",
      "18               Biography|Crime|Drama|Western         Katharine Ross   \n",
      "19            Comedy|Drama|Musical|Romance|War            Rock Hudson   \n",
      "20                          Comedy|Drama|Music         Charles Napier   \n",
      "21                   Documentary|History|Music             Joe Cocker   \n",
      "22                Drama|Family|Musical|Romance                  Topol   \n",
      "23                        Crime|Drama|Thriller              John Amos   \n",
      "24                               Drama|Fantasy             Don Brooks   \n",
      "25                                 Crime|Drama              Al Pacino   \n",
      "26                         Comedy|Crime|Horror                 Divine   \n",
      "27                                      Horror          Ellen Burstyn   \n",
      "28                          Comedy|Crime|Drama         Eileen Brennan   \n",
      "29                          Comedy|Drama|Music          Harrison Ford   \n",
      "...                                        ...                    ...   \n",
      "3192        Action|Biography|Drama|History|War    Matthew McConaughey   \n",
      "3193                   Horror|Mystery|Thriller           Javier Botet   \n",
      "3194                             Action|Comedy            Olivia Munn   \n",
      "3195                            Comedy|Romance            Alison Brie   \n",
      "3196          Action|Adventure|Sci-Fi|Thriller     Chloë Grace Moretz   \n",
      "3197                                    Comedy     Chloë Grace Moretz   \n",
      "3198                                    Comedy         Peter Dinklage   \n",
      "3199                     Action|Horror|Romance             Matt Smith   \n",
      "3200                      Crime|Drama|Thriller          Julia Roberts   \n",
      "3201                      Action|Drama|Western        Natalie Portman   \n",
      "3202                                    Comedy             Mila Kunis   \n",
      "3203                                    Comedy             Mila Kunis   \n",
      "3204            Action|Adventure|Drama|Mystery            Peter Firth   \n",
      "3205   Adventure|Crime|Mystery|Sci-Fi|Thriller           Samira Wiley   \n",
      "3206               Action|Crime|Drama|Thriller           Kate Winslet   \n",
      "3207                                     Drama          Clive Russell   \n",
      "3208                     Comedy|Family|Romance           Nia Vardalos   \n",
      "3209                     Drama|Horror|Thriller          Óscar Jaenada   \n",
      "3210      Drama|Horror|Mystery|Sci-Fi|Thriller         Bradley Cooper   \n",
      "3211                             Action|Comedy               Nia Long   \n",
      "3212                                     Drama        Jennifer Garner   \n",
      "3213                                    Comedy         Robert De Niro   \n",
      "3214                   Horror|Mystery|Thriller           Lauren Cohan   \n",
      "3215                   Horror|Mystery|Thriller            Eoin Macken   \n",
      "3216                                     Drama    Benjamin A. Onyango   \n",
      "3217                                    Comedy           Fred Willard   \n",
      "3218                            Comedy|Romance          Donald Faison   \n",
      "3219                                    Horror            Billy Burke   \n",
      "3220             Action|Drama|History|Thriller  Michael Raymond-James   \n",
      "3221                                     Drama           Logan Lerman   \n",
      "\n",
      "                              movie_title  num_voted_users  \\\n",
      "0                 The Lady from Shanghai             19236   \n",
      "1                             The Pirate              3258   \n",
      "2                     Annie Get Your Gun              3167   \n",
      "3             The Greatest Show on Earth              9456   \n",
      "4                               The Robe              6359   \n",
      "5          The Beast from 20,000 Fathoms              4812   \n",
      "6                      On the Waterfront            100890   \n",
      "7                       Some Like It Hot            175196   \n",
      "8                                 Psycho            422432   \n",
      "9                        West Side Story             71919   \n",
      "10       It's a Mad, Mad, Mad, Mad World             29323   \n",
      "11                          My Fair Lady             66959   \n",
      "12                          Mary Poppins            107408   \n",
      "13                     Nothing But a Man               891   \n",
      "14          The Greatest Story Ever Told              6484   \n",
      "15                        Doctor Zhivago             55816   \n",
      "16                    The Sound of Music            148172   \n",
      "17                          Major Dundee              5294   \n",
      "18    Butch Cassidy and the Sundance Kid            152089   \n",
      "19                          Darling Lili              1547   \n",
      "20        Beyond the Valley of the Dolls              7584   \n",
      "21                             Woodstock             12631   \n",
      "22                   Fiddler on the Roof             29839   \n",
      "23     Sweet Sweetback's Baadasssss Song              3340   \n",
      "24                        Pink Narcissus               803   \n",
      "25                         The Godfather           1155770   \n",
      "26                        Pink Flamingos             16792   \n",
      "27                          The Exorcist            284252   \n",
      "28                             The Sting            175607   \n",
      "29                     American Graffiti             63839   \n",
      "...                                   ...              ...   \n",
      "3192                 Free State of Jones              3077   \n",
      "3193                     The Conjuring 2             64989   \n",
      "3194                        Ride Along 2             28621   \n",
      "3195                    How to Be Single             39440   \n",
      "3196                        The 5th Wave             55617   \n",
      "3197        Neighbors 2: Sorority Rising             28041   \n",
      "3198                            The Boss             16984   \n",
      "3199     Pride and Prejudice and Zombies             23775   \n",
      "3200                       Money Monster             19611   \n",
      "3201                      Jane Got a Gun              8885   \n",
      "3202                            Bad Moms              4654   \n",
      "3203                            Bad Moms              4654   \n",
      "3204                               Risen             12276   \n",
      "3205                               Nerve              4303   \n",
      "3206                            Triple 9             32567   \n",
      "3207                   The Young Messiah              1449   \n",
      "3208          My Big Fat Greek Wedding 2             13562   \n",
      "3209                        The Shallows             12983   \n",
      "3210                 10 Cloverfield Lane            126893   \n",
      "3211                               Keanu             15385   \n",
      "3212                Miracles from Heaven              6276   \n",
      "3213                       Dirty Grandpa             49671   \n",
      "3214                             The Boy             35654   \n",
      "3215                          The Forest             20837   \n",
      "3216                    God's Not Dead 2              4501   \n",
      "3217               Fifty Shades of Black              9509   \n",
      "3218                   The Perfect Match              1180   \n",
      "3219                          Lights Out             13523   \n",
      "3220                    The Finest Hours             27481   \n",
      "3221                         Indignation               550   \n",
      "\n",
      "              actor_3_name  facenumber_in_poster  \\\n",
      "0            Ted de Corsia                   1.0   \n",
      "1               Ellen Ross                   0.0   \n",
      "2             Betty Hutton                   0.0   \n",
      "3             Cornel Wilde                   0.0   \n",
      "4            Victor Mature                   1.0   \n",
      "5             Ross Elliott                   0.0   \n",
      "6              Rod Steiger                   2.0   \n",
      "7              George Raft                   2.0   \n",
      "8               John Gavin                   2.0   \n",
      "9           Richard Beymer                   0.0   \n",
      "10           Spencer Tracy                   0.0   \n",
      "11          Theodore Bikel                   1.0   \n",
      "12         Elsa Lanchester                   2.0   \n",
      "13              Ivan Dixon                   1.0   \n",
      "14             José Ferrer                   6.0   \n",
      "15       Geraldine Chaplin                   2.0   \n",
      "16        Nicholas Hammond                   3.0   \n",
      "17            Warren Oates                   2.0   \n",
      "18            Kenneth Mars                   1.0   \n",
      "19             Jeremy Kemp                   2.0   \n",
      "20           Harrison Page                   8.0   \n",
      "21               Joan Baez                   0.0   \n",
      "22         Rosalind Harris                   0.0   \n",
      "23      Melvin Van Peebles                   1.0   \n",
      "24                     NaN                   1.0   \n",
      "25           Robert Duvall                   1.0   \n",
      "26            Edith Massey                   2.0   \n",
      "27             Lee J. Cobb                   0.0   \n",
      "28             Ray Walston                   0.0   \n",
      "29      Mackenzie Phillips                   1.0   \n",
      "...                    ...                   ...   \n",
      "3192       Jessica Collins                   1.0   \n",
      "3193    Robin Atkin Downes                   0.0   \n",
      "3194          Bruce McGill                   0.0   \n",
      "3195        Nicholas Braun                   4.0   \n",
      "3196         Nick Robinson                   0.0   \n",
      "3197       Kiersey Clemons                   0.0   \n",
      "3198           Ben Falcone                   1.0   \n",
      "3199             Sam Riley                   0.0   \n",
      "3200           Chris Bauer                   1.0   \n",
      "3201         Boyd Holbrook                   0.0   \n",
      "3202    Jada Pinkett Smith                   9.0   \n",
      "3203    Jada Pinkett Smith                   9.0   \n",
      "3204           María Botto                   2.0   \n",
      "3205           Emily Meade                   0.0   \n",
      "3206   Clifton Collins Jr.                   3.0   \n",
      "3207          Finn Ireland                   0.0   \n",
      "3208           Joey Fatone                  10.0   \n",
      "3209          Sedona Legge                   0.0   \n",
      "3210       Sumalee Montano                   0.0   \n",
      "3211    Keegan-Michael Key                   2.0   \n",
      "3212      Martin Henderson                   0.0   \n",
      "3213      Jason Mantzoukas                   1.0   \n",
      "3214     Stephanie Lemelin                   0.0   \n",
      "3215              Gen Seto                   1.0   \n",
      "3216  Maria Canals-Barrera                  11.0   \n",
      "3217        Russell Peters                   4.0   \n",
      "3218         Lauren London                   6.0   \n",
      "3219       Gabriel Bateman                   0.0   \n",
      "3220       Graham McTavish                   0.0   \n",
      "3221           Tracy Letts                   0.0   \n",
      "\n",
      "                                          plot_keywords  num_user_for_reviews  \\\n",
      "0               law partner|murder|partner|seaman|yacht                 175.0   \n",
      "1              hoop|horseback riding|love|pirate|singer                  54.0   \n",
      "2                    girl|gun|love|sharpshooter|the end                  90.0   \n",
      "3     circus|clown|elephant trainer|trapeze|trapeze ...                 107.0   \n",
      "4     box office hit|crucifixion|nightmare|palestine...                  69.0   \n",
      "5             arctic|beast|dinosaur|monster|rhedosaurus                  88.0   \n",
      "6                  death|dock|longshoreman|murder|union                 281.0   \n",
      "7      all girl band|band|cross dressing|musician|yacht                 350.0   \n",
      "8                         money|motel|rain|shower|theft                1040.0   \n",
      "9         dance|gang|new york city|puerto rican|tragedy                 316.0   \n",
      "10             california|desert|dying words|money|race                 344.0   \n",
      "11           colonel|flower girl|professor|street|wager                 258.0   \n",
      "12    banker|female protagonist|live action and anim...                 259.0   \n",
      "13                    1960s|father|railroad|town|worker                  26.0   \n",
      "14      70mm film|biblical epic|faith|jewish|king herod                 100.0   \n",
      "15      bolshevik|poet|poetry|russia|russian revolution                 255.0   \n",
      "16    austria|children|governess|love|orchestral mus...                 406.0   \n",
      "17        apache|apache indian|confederate|mexico|scout                  67.0   \n",
      "18                      bolivia|gang|outlaw|posse|train                 309.0   \n",
      "19        crepe suzette|french|mata hari spoof|song|spy                  50.0   \n",
      "20               band|drugs|friendship|hollywood|satire                 137.0   \n",
      "21        drugs|hippie|music festival|the who|woodstock                  63.0   \n",
      "22    immigration|jewish|pogrom|tradition|tradition ...                 150.0   \n",
      "23    black panther|hells angels|on the run|racist|r...                  50.0   \n",
      "24    male frontal nudity|male pubic hair|male rear ...                  16.0   \n",
      "25    crime family|mafia|organized crime|patriarch|r...                2238.0   \n",
      "26         absurd humor|egg|gross out humor|lesbian|sex                 183.0   \n",
      "27    demonic possession|exorcism|exorcist|loss of i...                1058.0   \n",
      "28                  con|con man|courier|long con|murder                 252.0   \n",
      "29    california|car|drag racing|high school|rock 'n...                 238.0   \n",
      "...                                                 ...                   ...   \n",
      "3192        american civil war|civil war|u.s. civil war                  47.0   \n",
      "3193  based on supposedly true story|house|paranorma...                 279.0   \n",
      "3194  computer hacker|crime boss|detective|drugs|wed...                  58.0   \n",
      "3195  motor scooter|new york city|newborn baby|scoot...                  83.0   \n",
      "3196  alien|attack|based on novel|based on young adu...                 266.0   \n",
      "3197  bare chested male|gay|gay best friend|gay man|...                 111.0   \n",
      "3198  business|girl scouts|orphanage|overweight woma...                  96.0   \n",
      "3199  based on novel|damsel in distress|deception|en...                 134.0   \n",
      "3200  death|hostage|money|shot in the chest|shot in ...                 103.0   \n",
      "3201  brothel|death of husband|ex lover|haunted by t...                  56.0   \n",
      "3202  lesbian kiss|mom|pta|reference to mad max|scen...                  46.0   \n",
      "3203  lesbian kiss|mom|pta|reference to mad max|scen...                  46.0   \n",
      "3204  biblical|crucifixion|judea|resurrection|roman ...                 117.0   \n",
      "3205       dare|game|knocked out|motorcycle|online game                  35.0   \n",
      "3206  betrayal|corrupt cop|heist|murder of a police ...                 106.0   \n",
      "3207                                     based on novel                  30.0   \n",
      "3208  family restaurant|greek|remarriage|suburb|wedding                 103.0   \n",
      "3209                   beach|island|mexico|prey|trapped                 139.0   \n",
      "3210     alien|bunker|car crash|kidnapping|minimal cast                 440.0   \n",
      "3211          car chase|gangsta|gun fight|hitman|kitten                  84.0   \n",
      "3212  child cancer|christian film|christianity|falli...                  55.0   \n",
      "3213  female removes her clothes|fondling|voyeur|voy...                 166.0   \n",
      "3214    animate doll|doll|england|nanny|surprise ending                 155.0   \n",
      "3215   forest|japan|suicide|suicide forest|supernatural                 127.0   \n",
      "3216  alternate universe|christian|christian film|ch...                 102.0   \n",
      "3217  color in title|parody|reference to cuba goodin...                  53.0   \n",
      "3218                                                NaN                   9.0   \n",
      "3219  based on short film|reference to avenged seven...                  95.0   \n",
      "3220  1950s|coast guard|oil tanker|sinking ship|surv...                 113.0   \n",
      "3221                                     based on novel                   3.0   \n",
      "\n",
      "     content_rating        budget  title_year  imdb_score  \n",
      "0         Not Rated  2.614410e+07        1947         7.7  \n",
      "1          Approved  3.815070e+07        1948         7.1  \n",
      "2            Passed  3.913883e+07        1950         7.0  \n",
      "3         Not Rated  3.692400e+07        1952         6.7  \n",
      "4           Unrated  4.582500e+07        1953         6.8  \n",
      "5          Approved  1.924650e+06        1953         6.7  \n",
      "6         Not Rated  8.247330e+06        1954         8.2  \n",
      "7         Not Rated  2.427046e+07        1959         8.3  \n",
      "8                 R  6.708150e+06        1960         8.5  \n",
      "9           Unrated  4.909200e+07        1961         7.6  \n",
      "10         Approved  7.539740e+07        1963         7.6  \n",
      "11         Approved  1.341470e+08        1964         7.9  \n",
      "12         Approved  4.734600e+07        1964         7.8  \n",
      "13        Not Rated  1.262560e+06        1964         8.1  \n",
      "14                G  1.561200e+08        1965         6.6  \n",
      "15            PG-13  8.586600e+07        1965         8.0  \n",
      "16                G  6.400920e+07        1965         8.0  \n",
      "17         Approved  2.966280e+07        1965         6.8  \n",
      "18                M  4.103400e+07        1969         8.1  \n",
      "19                G  1.610500e+08        1970         6.2  \n",
      "20                X  5.797800e+06        1970         6.2  \n",
      "21                R  3.865200e+06        1970         8.1  \n",
      "22                G  5.507100e+07        1971         8.0  \n",
      "23                R  3.059500e+06        1971         5.5  \n",
      "24        Not Rated  1.652130e+05        1971         6.7  \n",
      "25                R  3.555600e+07        1972         9.2  \n",
      "26            NC-17  5.926000e+04        1972         6.1  \n",
      "27                R  4.574400e+07        1973         8.0  \n",
      "28               PG  3.144900e+07        1973         8.3  \n",
      "29               PG  4.442886e+06        1973         7.5  \n",
      "...             ...           ...         ...         ...  \n",
      "3192              R  5.125000e+07        2016         6.7  \n",
      "3193              R  4.100000e+07        2016         7.8  \n",
      "3194          PG-13  4.100000e+07        2016         5.9  \n",
      "3195              R  3.895000e+07        2016         6.1  \n",
      "3196          PG-13  3.895000e+07        2016         5.2  \n",
      "3197              R  3.587500e+07        2016         6.0  \n",
      "3198              R  2.972500e+07        2016         5.3  \n",
      "3199          PG-13  2.870000e+07        2016         5.8  \n",
      "3200              R  2.767500e+07        2016         6.7  \n",
      "3201              R  2.562500e+07        2016         5.8  \n",
      "3202              R  2.050000e+07        2016         6.7  \n",
      "3203              R  2.050000e+07        2016         6.7  \n",
      "3204          PG-13  2.050000e+07        2016         6.3  \n",
      "3205          PG-13  2.050000e+07        2016         7.1  \n",
      "3206              R  2.050000e+07        2016         6.3  \n",
      "3207          PG-13  1.896250e+07        2016         5.4  \n",
      "3208          PG-13  1.845000e+07        2016         6.1  \n",
      "3209          PG-13  1.742500e+07        2016         6.8  \n",
      "3210          PG-13  1.537500e+07        2016         7.3  \n",
      "3211              R  1.537500e+07        2016         6.4  \n",
      "3212             PG  1.332500e+07        2016         6.8  \n",
      "3213              R  1.178750e+07        2016         6.0  \n",
      "3214          PG-13  1.025000e+07        2016         6.0  \n",
      "3215          PG-13  1.025000e+07        2016         4.8  \n",
      "3216             PG  5.125000e+06        2016         3.4  \n",
      "3217              R  5.125000e+06        2016         3.5  \n",
      "3218              R  5.125000e+06        2016         4.5  \n",
      "3219          PG-13  5.022500e+06        2016         6.9  \n",
      "3220          PG-13           NaN        2016         6.8  \n",
      "3221              R           NaN        2016         7.8  \n",
      "\n",
      "[3222 rows x 18 columns]\n",
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def adjust(dollars):\n",
    "    return df_inflation.iloc[(list(np.where(df_inflation[\"DATE\"] == 1947)[0]))]['VALUE'].values[0]\n",
    "\n",
    "# print(df['gross'][0] * df_inflation.iloc[(list(np.where(df_inflation[\"DATE\"] == num)[0]))]['VALUE'].values[0])\n",
    "\n",
    "for x in range(0, len(df)):\n",
    "    adjusted = list(np.where(df_inflation[\"DATE\"] == df['title_year'][x])[0])\n",
    "    adjusted = df_inflation.iloc[adjusted]['VALUE'].values[0]\n",
    "    df['gross'][x] = df['gross'][x] * adjusted \n",
    "    df['budget'][x] = df['budget'][x] * adjusted\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tamper with the groupings to improve imputations? How do we improve how many values get imputed?\n",
    "df_grouped = df.groupby(by=['director_name'])\n",
    "# director_name adds about 50 rows (imputes about 50 rows and then deletes about 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3232 entries, 0 to 3231\n",
      "Data columns (total 18 columns):\n",
      "num_critic_for_reviews    3229 non-null float64\n",
      "duration                  3231 non-null float64\n",
      "gross                     3232 non-null int64\n",
      "num_voted_users           3232 non-null int64\n",
      "facenumber_in_poster      3232 non-null float64\n",
      "num_user_for_reviews      3231 non-null float64\n",
      "budget                    3159 non-null float64\n",
      "title_year                3232 non-null int64\n",
      "imdb_score                3232 non-null float64\n",
      "actor_2_name              3229 non-null object\n",
      "movie_title               3232 non-null object\n",
      "actor_1_name              3230 non-null object\n",
      "color                     3231 non-null object\n",
      "plot_keywords             3208 non-null object\n",
      "genres                    3232 non-null object\n",
      "content_rating            3206 non-null object\n",
      "director_name             3232 non-null object\n",
      "actor_3_name              3225 non-null object\n",
      "dtypes: float64(6), int64(3), object(9)\n",
      "memory usage: 454.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_imputed = df_grouped.transform(lambda grp: grp.fillna(grp.median()))\n",
    "col_deleted = list( set(df.columns) - set(df_imputed.columns)) #in case the median op deleted columns\n",
    "df_imputed[col_deleted] = df[col_deleted]\n",
    "\n",
    "print(df_imputed.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3119 entries, 0 to 3230\n",
      "Data columns (total 18 columns):\n",
      "num_critic_for_reviews    3119 non-null float64\n",
      "duration                  3119 non-null float64\n",
      "gross                     3119 non-null int64\n",
      "num_voted_users           3119 non-null int64\n",
      "facenumber_in_poster      3119 non-null float64\n",
      "num_user_for_reviews      3119 non-null float64\n",
      "budget                    3119 non-null float64\n",
      "title_year                3119 non-null int64\n",
      "imdb_score                3119 non-null float64\n",
      "actor_2_name              3119 non-null object\n",
      "movie_title               3119 non-null object\n",
      "actor_1_name              3119 non-null object\n",
      "color                     3119 non-null object\n",
      "plot_keywords             3119 non-null object\n",
      "genres                    3119 non-null object\n",
      "content_rating            3119 non-null object\n",
      "director_name             3119 non-null object\n",
      "actor_3_name              3119 non-null object\n",
      "dtypes: float64(6), int64(3), object(9)\n",
      "memory usage: 463.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# drop rows that still have missing values after imputation\n",
    "df_imputed.dropna(inplace=True)\n",
    "print (df_imputed.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirement: ** [15 points] Divide you data into training and testing data using an 80% training and 20% testing split. Use the cross validation modules that are part of scikit-learn. Argue for or against splitting your data using an 80/20 split. That is, why is the 80/20 split appropriate (or not) for your dataset?  \n",
    "\n",
    "### Split Up the Data Now\n",
    "\n",
    "Below we split up the data into testing and training sets. We use the train_test_split function from sklearn to achieve splittling and cross validation of the data set. In this way we have an averaged training and testing set to use for our model. We decided to use an 80/20 split (that is, 80% of the set is used for training, 20% is used for testing), as that seemed to be the best breakdown for our data as mentioned through several <a href=\"http://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio\">stack overflow posts</a>. \n",
    "\n",
    "We want to balance the tradeoffs between having a smaller training set and having a smaller testing set. With less training data we risk having greater variance in our parameter estimates, with less testing data we will have a greater variance in our performance statistics. The best case is to balance the effects of both, by running a few different splits and seeing what variance we get on different splits. It seemed that the 80/20 split was the best option for our dataset and gave us the least variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2495 624\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "train_set, test_set = model_selection.train_test_split(df_imputed, test_size=0.2, train_size=0.8, random_state= 101)\n",
    "print(len(train_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Modeling (50 points total)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# But First... A Super Cool Custom Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirement**: [20 points] Create a custom, one-versus-all logistic regression classifier using numpy and scipy to optimize. Use object oriented conventions identical to scikit-learn. You should start with the template used in the course. You should add the following functionality to the logistic regression classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.special import expit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from last time, our logistic regression algorithm is given by (including everything we previously had):\n",
    "class BinaryLogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.001):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "        \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    # convenience, private:\n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # vectorized gradient calculation with regularization using L2 Norm\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += 2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self,X,add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class StochasticBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # stochastic gradient calculation \n",
    "    def _get_gradient(self,X,y):\n",
    "        idx = int(np.random.rand()*len(y)) # grab random instance\n",
    "        ydiff = y[idx]-self.predict_proba(X[idx],add_bias=False) # get y difference (now scalar)\n",
    "        gradient = X[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import pinv\n",
    "class HessianBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # just overwrite gradient function\n",
    "    def _get_gradient(self,X,y):\n",
    "        g = self.predict_proba(X,add_bias=False).ravel() # get sigmoid value for all classes\n",
    "        hessian = X.T @ np.diag(g*(1-g)) @ X - 2 * self.C # calculate the hessian\n",
    "\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.sum(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return pinv(hessian) @ gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.001, optimizer=\"steep_desc\"):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        self.optimizer = optimizer\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.sort(np.unique(y)) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = []\n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            if self.optimizer == \"steep_desc\":\n",
    "                blr = BinaryLogisticRegression(self.eta, self.iters, self.C) #??\n",
    "            elif self.optimizer == \"stoch_grad\":\n",
    "                blr = StochasticBinaryLogisticRegression(self.eta, self.iters, self.C)\n",
    "            elif self.optimizer == \"newton\":\n",
    "                blr = HessianBinaryLogisticRegression(self.eta, self.iters, self.C)\n",
    "                \n",
    "            y_binary = y==yval # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr.fit(X,y_binary)\n",
    "            #print(accuracy(y_binary,bin_class.predict(X)))\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T    \n",
    "       \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier  ##go through the list of classifiers and get predictions for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_proba(X),axis=1) # take argmax along row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "**Requirement**: Ability to choose optimization technique when class is instantiated: either steepest descent, stochastic gradient descent, or Newton's method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Logistic Regression Object with coefficients:\n",
      "[[  0.0568186 ]\n",
      " [ 11.09977003]\n",
      " [ -2.83792666]\n",
      " [ 28.01308577]\n",
      " [ 12.18540831]]\n",
      "Accuracy of:  0.333333333333\n",
      "--------------------\n",
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[ 0.52879022  0.54676794  1.84290504 -2.84149853 -1.27734932]\n",
      " [ 2.34104606  0.83136796 -3.48736467  0.69307076 -3.70719668]\n",
      " [-3.11112375 -3.13706296 -3.20776378  4.59588805  4.99071128]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 0 1 2 1 2 1 2 0 0 2 1 2 1 2 0 2 1\n",
      " 1 0 1 2 2 0 1 1 0 2 2 2 2 1 0 2 2 2 1 1 2 0 2 1 0 0 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Accuracy of:  0.76\n",
      "----------------\n",
      "<class 'numpy.ndarray'>\n",
      "(150,)\n",
      "Wall time: 580 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Linear Regression Testing\n",
    "ds = load_iris()\n",
    "X = ds.data\n",
    "y = ds.target # note problem is NOT binary anymore, there are three classes!\n",
    "# y = (ds.target>1).astype(np.int) # make problem binary\n",
    "\n",
    "blr = BinaryLogisticRegression(0.1, 200, C=.001)\n",
    "blr.fit(X,y)\n",
    "print(blr)\n",
    "yhat = blr.predict(X)\n",
    "print('Accuracy of: ',accuracy_score(y,yhat)) \n",
    "\n",
    "print(\"--------------------\")\n",
    "\n",
    "lr = LogisticRegression(0.1,3000,C=0.001, optimizer=\"stoch_grad\")\n",
    "lr.fit(X,y)\n",
    "print(lr)\n",
    "yhat = lr.predict(X)\n",
    "\n",
    "print(yhat)\n",
    "print('Accuracy of: ',accuracy_score(y,yhat))\n",
    "\n",
    "print('----------------')\n",
    "print(type(X))\n",
    "print(y.shape)\n",
    "# print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.30000000e+01   1.02000000e+02   1.99860000e+04 ...,   4.00000000e+07\n",
      "    2.00100000e+03   6.20000000e+00]\n",
      " [  1.50000000e+01   8.70000000e+01   2.30800000e+03 ...,   4.00000000e+06\n",
      "    1.98700000e+03   4.80000000e+00]\n",
      " [  8.50000000e+01   1.06000000e+02   2.26490000e+04 ...,   2.10000000e+07\n",
      "    2.00100000e+03   6.30000000e+00]\n",
      " ..., \n",
      " [  1.49000000e+02   1.35000000e+02   7.70290000e+04 ...,   6.00000000e+07\n",
      "    2.00300000e+03   5.40000000e+00]\n",
      " [  5.00000000e+01   9.10000000e+01   1.21880000e+04 ...,   3.50000000e+06\n",
      "    2.00400000e+03   5.30000000e+00]\n",
      " [  1.60000000e+01   1.02000000e+02   2.29500000e+03 ...,   2.10000000e+07\n",
      "    1.99900000e+03   5.80000000e+00]]\n",
      "Wall time: 3.51 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(0.1, 1000, C=0.001, optimizer=\"stoch_grad\")\n",
    "# print(train_set)\n",
    "X = train_set.drop(['gross', 'movie_title', 'director_name', 'plot_keywords', 'actor_1_name', 'actor_3_name', 'genres',\n",
    "                   'actor_2_name', 'content_rating', 'color'], axis=1).values\n",
    "y = train_set['gross'].values\n",
    "\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 57.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr.fit(X,y)\n",
    "yhat = lr.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6114237   800000 40219708 ..., 31111260    96793    15593]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "Accuracy of:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(yhat)\n",
    "print('Accuracy of: ',accuracy_score(y,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Requirement: ** Update the gradient calculation to include a customizable regularization term (either using no regularization, L1 regularization, L2 regularization, or both L1/L2 norm of the weights). Associate a cost with the regularization term, \"C\", that can be adjusted when the class is instantiated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirement: ** [15 points] Train your classifier to achieve good generalization performance. That is, adjust the optimization technique and the value of the regularization term \"C\" to achieve the best performance on your test set. Is your method of selecting parameters justified? That is, do you think there is any \"data snooping\" involved with this method of selecting parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirement: ** [15 points] Compare the performance of your \"best\" logistic regression optimization procedure to the procedure used in scikit-learn. Visualize the performance differences in terms of training time, training iterations, and memory usage while training. Discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Deployment (10 points total)*\n",
    "**Requirement: **Which implementation of logistic regression would you advise be used in a deployed machine learning model, your implementation or scikit-learn (or other third party)? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exceptional Work (10 points total)*\n",
    "**Rerquirement: ** You have free reign to provide additional analyses.\n",
    "One idea: Make your implementation of logistic regression compatible with the GridSearchCV function that is part of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
